Search.setIndex({"docnames": ["_autosummary/speechtotext", "_autosummary/speechtotext.benchmark", "_autosummary/speechtotext.benchmark.benchmarks", "_autosummary/speechtotext.benchmark.benchmarks.Benchmark", "_autosummary/speechtotext.benchmark.benchmarks.run_benchmarks", "_autosummary/speechtotext.benchmark.customBenchmarks", "_autosummary/speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark", "_autosummary/speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark", "_autosummary/speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark", "_autosummary/speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark", "_autosummary/speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark", "_autosummary/speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark", "_autosummary/speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark", "_autosummary/speechtotext.benchmark.customBenchmarks.WhisperBenchmark", "_autosummary/speechtotext.datasets", "_autosummary/speechtotext.datasets.Dataset", "_autosummary/speechtotext.datasets.DatasetBare", "_autosummary/speechtotext.datasets.SampleDataset", "_autosummary/speechtotext.functions", "_autosummary/speechtotext.functions.BaseResult", "_autosummary/speechtotext.functions.DEFAULT_CSV_NAME", "_autosummary/speechtotext.functions.DEFAULT_DATETIME_FORMAT", "_autosummary/speechtotext.functions.DEFAULT_REPORTS_FOLDER", "_autosummary/speechtotext.functions.NoTranscriptReturned", "_autosummary/speechtotext.functions.REGEX_STRING_PARSE", "_autosummary/speechtotext.functions.RequiredEnvVariablesMissing", "_autosummary/speechtotext.functions.benchmark_results_to_csv", "_autosummary/speechtotext.functions.force_cudnn_initialization", "_autosummary/speechtotext.functions.get_extention_of_file_name", "_autosummary/speechtotext.functions.get_file_name_without_extention", "_autosummary/speechtotext.functions.join_benchmark_results", "_autosummary/speechtotext.functions.load_env_variable", "_autosummary/speechtotext.functions.multidispatch", "_autosummary/speechtotext.functions.save_folder_name", "_autosummary/speechtotext.functions.save_sub_folder_name", "_autosummary/speechtotext.functions.separate_benchmark_results_by_model", "_autosummary/speechtotext.functions.string_cleaning", "_autosummary/speechtotext.functions.timing", "_autosummary/speechtotext.functions.uppercase_for_first_character_in_string", "_autosummary/speechtotext.metric", "_autosummary/speechtotext.metric.customMetrics", "_autosummary/speechtotext.metric.customMetrics.BaseMetrics", "_autosummary/speechtotext.metric.customMetrics.BenchmarkResults", "_autosummary/speechtotext.metric.customMetrics.ErrorMetrics", "_autosummary/speechtotext.metric.customMetrics.ResultMetrics", "_autosummary/speechtotext.metric.metrics", "_autosummary/speechtotext.metric.metrics.Metrics", "_autosummary/speechtotext.model", "_autosummary/speechtotext.model.amazonWrapper", "_autosummary/speechtotext.model.amazonWrapper.AmazonAPIVersion", "_autosummary/speechtotext.model.amazonWrapper.AmazonAPIWrapper", "_autosummary/speechtotext.model.amazonWrapper.amazon_delete_job", "_autosummary/speechtotext.model.assemblyAIWrapper", "_autosummary/speechtotext.model.assemblyAIWrapper.AssemblyAIAPIVersion", "_autosummary/speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper", "_autosummary/speechtotext.model.azureWrapper", "_autosummary/speechtotext.model.azureWrapper.AzureAPIVersion", "_autosummary/speechtotext.model.azureWrapper.AzureAPIWrapper", "_autosummary/speechtotext.model.azureWrapper.AzureCancellation", "_autosummary/speechtotext.model.azureWrapper.AzureNoMatch", "_autosummary/speechtotext.model.deepgramWrapper", "_autosummary/speechtotext.model.deepgramWrapper.DeepgramAPIVersion", "_autosummary/speechtotext.model.deepgramWrapper.DeepgramAPIWrapper", "_autosummary/speechtotext.model.googleWrapper", "_autosummary/speechtotext.model.googleWrapper.GoogleAPIVersion", "_autosummary/speechtotext.model.googleWrapper.GoogleAPIWrapper", "_autosummary/speechtotext.model.modelWrapper", "_autosummary/speechtotext.model.modelWrapper.MetaModelWrapper", "_autosummary/speechtotext.model.modelWrapper.ModelVersion", "_autosummary/speechtotext.model.modelWrapper.ModelWrapper", "_autosummary/speechtotext.model.speechmaticsWrapper", "_autosummary/speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIVersion", "_autosummary/speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper", "_autosummary/speechtotext.model.whisperWrapper", "_autosummary/speechtotext.model.whisperWrapper.WhisperAPIVersion", "_autosummary/speechtotext.model.whisperWrapper.WhisperAPIWrapper", "_autosummary/speechtotext.model.whisperWrapper.WhisperVersion", "_autosummary/speechtotext.model.whisperWrapper.WhisperWrapper", "_autosummary/speechtotext.plot", "_autosummary/speechtotext.plot.customErrorPlots", "_autosummary/speechtotext.plot.customErrorPlots.ErrorCountByModel", "_autosummary/speechtotext.plot.customErrorPlots.ErrorCountByModelByDataset", "_autosummary/speechtotext.plot.customErrorPlots.ErrorCountHeatmap", "_autosummary/speechtotext.plot.customPlots", "_autosummary/speechtotext.plot.customPlots.DynamicallyByModelNameByDataset", "_autosummary/speechtotext.plot.customPlots.DynamicallyByModelNameForEachDataset", "_autosummary/speechtotext.plot.customPlots.MetricHeatMap", "_autosummary/speechtotext.plot.plotting", "_autosummary/speechtotext.plot.plotting.BaseMatPlotLib", "_autosummary/speechtotext.plot.plotting.BasePlotly", "_autosummary/speechtotext.plot.plotting.DynamicPlotClassesByMetricByDataset", "_autosummary/speechtotext.plot.plotting.DynamicPlotClassesByMetricForEachDataset", "_autosummary/speechtotext.plot.plotting.Plotting", "api", "examples", "index", "installation", "requirements"], "filenames": ["_autosummary/speechtotext.rst", "_autosummary/speechtotext.benchmark.rst", "_autosummary/speechtotext.benchmark.benchmarks.rst", "_autosummary/speechtotext.benchmark.benchmarks.Benchmark.rst", "_autosummary/speechtotext.benchmark.benchmarks.run_benchmarks.rst", "_autosummary/speechtotext.benchmark.customBenchmarks.rst", "_autosummary/speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark.rst", "_autosummary/speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark.rst", "_autosummary/speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark.rst", "_autosummary/speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark.rst", "_autosummary/speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark.rst", "_autosummary/speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark.rst", "_autosummary/speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark.rst", "_autosummary/speechtotext.benchmark.customBenchmarks.WhisperBenchmark.rst", "_autosummary/speechtotext.datasets.rst", "_autosummary/speechtotext.datasets.Dataset.rst", "_autosummary/speechtotext.datasets.DatasetBare.rst", "_autosummary/speechtotext.datasets.SampleDataset.rst", "_autosummary/speechtotext.functions.rst", "_autosummary/speechtotext.functions.BaseResult.rst", "_autosummary/speechtotext.functions.DEFAULT_CSV_NAME.rst", "_autosummary/speechtotext.functions.DEFAULT_DATETIME_FORMAT.rst", "_autosummary/speechtotext.functions.DEFAULT_REPORTS_FOLDER.rst", "_autosummary/speechtotext.functions.NoTranscriptReturned.rst", "_autosummary/speechtotext.functions.REGEX_STRING_PARSE.rst", "_autosummary/speechtotext.functions.RequiredEnvVariablesMissing.rst", "_autosummary/speechtotext.functions.benchmark_results_to_csv.rst", "_autosummary/speechtotext.functions.force_cudnn_initialization.rst", "_autosummary/speechtotext.functions.get_extention_of_file_name.rst", "_autosummary/speechtotext.functions.get_file_name_without_extention.rst", "_autosummary/speechtotext.functions.join_benchmark_results.rst", "_autosummary/speechtotext.functions.load_env_variable.rst", "_autosummary/speechtotext.functions.multidispatch.rst", "_autosummary/speechtotext.functions.save_folder_name.rst", "_autosummary/speechtotext.functions.save_sub_folder_name.rst", "_autosummary/speechtotext.functions.separate_benchmark_results_by_model.rst", "_autosummary/speechtotext.functions.string_cleaning.rst", "_autosummary/speechtotext.functions.timing.rst", "_autosummary/speechtotext.functions.uppercase_for_first_character_in_string.rst", "_autosummary/speechtotext.metric.rst", "_autosummary/speechtotext.metric.customMetrics.rst", "_autosummary/speechtotext.metric.customMetrics.BaseMetrics.rst", "_autosummary/speechtotext.metric.customMetrics.BenchmarkResults.rst", "_autosummary/speechtotext.metric.customMetrics.ErrorMetrics.rst", "_autosummary/speechtotext.metric.customMetrics.ResultMetrics.rst", "_autosummary/speechtotext.metric.metrics.rst", "_autosummary/speechtotext.metric.metrics.Metrics.rst", "_autosummary/speechtotext.model.rst", "_autosummary/speechtotext.model.amazonWrapper.rst", "_autosummary/speechtotext.model.amazonWrapper.AmazonAPIVersion.rst", "_autosummary/speechtotext.model.amazonWrapper.AmazonAPIWrapper.rst", "_autosummary/speechtotext.model.amazonWrapper.amazon_delete_job.rst", "_autosummary/speechtotext.model.assemblyAIWrapper.rst", "_autosummary/speechtotext.model.assemblyAIWrapper.AssemblyAIAPIVersion.rst", "_autosummary/speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper.rst", "_autosummary/speechtotext.model.azureWrapper.rst", "_autosummary/speechtotext.model.azureWrapper.AzureAPIVersion.rst", "_autosummary/speechtotext.model.azureWrapper.AzureAPIWrapper.rst", "_autosummary/speechtotext.model.azureWrapper.AzureCancellation.rst", "_autosummary/speechtotext.model.azureWrapper.AzureNoMatch.rst", "_autosummary/speechtotext.model.deepgramWrapper.rst", "_autosummary/speechtotext.model.deepgramWrapper.DeepgramAPIVersion.rst", "_autosummary/speechtotext.model.deepgramWrapper.DeepgramAPIWrapper.rst", "_autosummary/speechtotext.model.googleWrapper.rst", "_autosummary/speechtotext.model.googleWrapper.GoogleAPIVersion.rst", "_autosummary/speechtotext.model.googleWrapper.GoogleAPIWrapper.rst", "_autosummary/speechtotext.model.modelWrapper.rst", "_autosummary/speechtotext.model.modelWrapper.MetaModelWrapper.rst", "_autosummary/speechtotext.model.modelWrapper.ModelVersion.rst", "_autosummary/speechtotext.model.modelWrapper.ModelWrapper.rst", "_autosummary/speechtotext.model.speechmaticsWrapper.rst", "_autosummary/speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIVersion.rst", "_autosummary/speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper.rst", "_autosummary/speechtotext.model.whisperWrapper.rst", "_autosummary/speechtotext.model.whisperWrapper.WhisperAPIVersion.rst", "_autosummary/speechtotext.model.whisperWrapper.WhisperAPIWrapper.rst", "_autosummary/speechtotext.model.whisperWrapper.WhisperVersion.rst", "_autosummary/speechtotext.model.whisperWrapper.WhisperWrapper.rst", "_autosummary/speechtotext.plot.rst", "_autosummary/speechtotext.plot.customErrorPlots.rst", "_autosummary/speechtotext.plot.customErrorPlots.ErrorCountByModel.rst", "_autosummary/speechtotext.plot.customErrorPlots.ErrorCountByModelByDataset.rst", "_autosummary/speechtotext.plot.customErrorPlots.ErrorCountHeatmap.rst", "_autosummary/speechtotext.plot.customPlots.rst", "_autosummary/speechtotext.plot.customPlots.DynamicallyByModelNameByDataset.rst", "_autosummary/speechtotext.plot.customPlots.DynamicallyByModelNameForEachDataset.rst", "_autosummary/speechtotext.plot.customPlots.MetricHeatMap.rst", "_autosummary/speechtotext.plot.plotting.rst", "_autosummary/speechtotext.plot.plotting.BaseMatPlotLib.rst", "_autosummary/speechtotext.plot.plotting.BasePlotly.rst", "_autosummary/speechtotext.plot.plotting.DynamicPlotClassesByMetricByDataset.rst", "_autosummary/speechtotext.plot.plotting.DynamicPlotClassesByMetricForEachDataset.rst", "_autosummary/speechtotext.plot.plotting.Plotting.rst", "api.rst", "examples.rst", "index.rst", "installation.rst", "requirements.rst"], "titles": ["speechtotext", "speechtotext.benchmark", "speechtotext.benchmark.benchmarks", "speechtotext.benchmark.benchmarks.Benchmark", "speechtotext.benchmark.benchmarks.run_benchmarks", "speechtotext.benchmark.customBenchmarks", "speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark", "speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark", "speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark", "speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark", "speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark", "speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark", "speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark", "speechtotext.benchmark.customBenchmarks.WhisperBenchmark", "speechtotext.datasets", "speechtotext.datasets.Dataset", "speechtotext.datasets.DatasetBare", "speechtotext.datasets.SampleDataset", "speechtotext.functions", "speechtotext.functions.BaseResult", "speechtotext.functions.DEFAULT_CSV_NAME", "speechtotext.functions.DEFAULT_DATETIME_FORMAT", "speechtotext.functions.DEFAULT_REPORTS_FOLDER", "speechtotext.functions.NoTranscriptReturned", "speechtotext.functions.REGEX_STRING_PARSE", "speechtotext.functions.RequiredEnvVariablesMissing", "speechtotext.functions.benchmark_results_to_csv", "speechtotext.functions.force_cudnn_initialization", "speechtotext.functions.get_extention_of_file_name", "speechtotext.functions.get_file_name_without_extention", "speechtotext.functions.join_benchmark_results", "speechtotext.functions.load_env_variable", "speechtotext.functions.multidispatch", "speechtotext.functions.save_folder_name", "speechtotext.functions.save_sub_folder_name", "speechtotext.functions.separate_benchmark_results_by_model", "speechtotext.functions.string_cleaning", "speechtotext.functions.timing", "speechtotext.functions.uppercase_for_first_character_in_string", "speechtotext.metric", "speechtotext.metric.customMetrics", "speechtotext.metric.customMetrics.BaseMetrics", "speechtotext.metric.customMetrics.BenchmarkResults", "speechtotext.metric.customMetrics.ErrorMetrics", "speechtotext.metric.customMetrics.ResultMetrics", "speechtotext.metric.metrics", "speechtotext.metric.metrics.Metrics", "speechtotext.model", "speechtotext.model.amazonWrapper", "speechtotext.model.amazonWrapper.AmazonAPIVersion", "speechtotext.model.amazonWrapper.AmazonAPIWrapper", "speechtotext.model.amazonWrapper.amazon_delete_job", "speechtotext.model.assemblyAIWrapper", "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIVersion", "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper", "speechtotext.model.azureWrapper", "speechtotext.model.azureWrapper.AzureAPIVersion", "speechtotext.model.azureWrapper.AzureAPIWrapper", "speechtotext.model.azureWrapper.AzureCancellation", "speechtotext.model.azureWrapper.AzureNoMatch", "speechtotext.model.deepgramWrapper", "speechtotext.model.deepgramWrapper.DeepgramAPIVersion", "speechtotext.model.deepgramWrapper.DeepgramAPIWrapper", "speechtotext.model.googleWrapper", "speechtotext.model.googleWrapper.GoogleAPIVersion", "speechtotext.model.googleWrapper.GoogleAPIWrapper", "speechtotext.model.modelWrapper", "speechtotext.model.modelWrapper.MetaModelWrapper", "speechtotext.model.modelWrapper.ModelVersion", "speechtotext.model.modelWrapper.ModelWrapper", "speechtotext.model.speechmaticsWrapper", "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIVersion", "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper", "speechtotext.model.whisperWrapper", "speechtotext.model.whisperWrapper.WhisperAPIVersion", "speechtotext.model.whisperWrapper.WhisperAPIWrapper", "speechtotext.model.whisperWrapper.WhisperVersion", "speechtotext.model.whisperWrapper.WhisperWrapper", "speechtotext.plot", "speechtotext.plot.customErrorPlots", "speechtotext.plot.customErrorPlots.ErrorCountByModel", "speechtotext.plot.customErrorPlots.ErrorCountByModelByDataset", "speechtotext.plot.customErrorPlots.ErrorCountHeatmap", "speechtotext.plot.customPlots", "speechtotext.plot.customPlots.DynamicallyByModelNameByDataset", "speechtotext.plot.customPlots.DynamicallyByModelNameForEachDataset", "speechtotext.plot.customPlots.MetricHeatMap", "speechtotext.plot.plotting", "speechtotext.plot.plotting.BaseMatPlotLib", "speechtotext.plot.plotting.BasePlotly", "speechtotext.plot.plotting.DynamicPlotClassesByMetricByDataset", "speechtotext.plot.plotting.DynamicPlotClassesByMetricForEachDataset", "speechtotext.plot.plotting.Plotting", "speechtotext", "Code Examples for speechtotext", "Welcome to speechtotext\u2019s documentation!", "Installation for speechtotext", "Requirements for speechtotext"], "terms": {"modul": [2, 5, 14, 18, 40, 45, 48, 52, 55, 60, 63, 66, 70, 73, 79, 83, 87, 94, 95], "us": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 18, 21, 24, 27, 37, 40, 41, 45, 46, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 66, 69, 70, 72, 73, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92], "thi": [2, 5, 14, 18, 40, 42, 43, 44, 45, 48, 49, 51, 52, 55, 60, 63, 66, 70, 73, 79, 83, 87, 90, 91, 92, 94, 97], "like": [2, 5, 14, 18, 40, 45, 48, 52, 55, 60, 63, 66, 70, 73, 79, 83, 87, 94], "import": [2, 5, 14, 18, 40, 45, 48, 52, 55, 60, 63, 66, 70, 73, 79, 83, 87, 94], "from": [2, 5, 14, 15, 18, 26, 40, 45, 48, 50, 52, 54, 55, 60, 63, 66, 70, 73, 79, 83, 87, 88, 89, 94], "dataset": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 66, 69, 70, 72, 73, 75, 77, 91, 92, 94, 97], "set": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 30, 46, 50, 54, 57, 62, 65, 69, 72, 75, 77, 94], "number_of_sampl": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 66, 69, 70, 72, 73, 75, 77, 94], "10": [2, 5, 14, 48, 52, 55, 60, 63, 66, 70, 73], "report_nam": [2, 4, 33, 87, 92, 94], "report": [2, 4, 19, 20, 22, 26, 33, 41, 42, 43, 44, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92], "name": [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 28, 29, 31, 33, 34, 41, 42, 43, 44, 46, 48, 50, 51, 52, 55, 60, 63, 66, 67, 70, 73, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92, 94, 96, 97], "path_to_dir": [2, 5, 14, 15, 16, 17, 48, 52, 55, 60, 63, 66, 70, 73, 94], "path": [2, 5, 14, 15, 16, 17, 19, 20, 33, 34, 41, 42, 43, 44, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 66, 69, 70, 72, 73, 75, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 94, 97], "dir": [2, 5, 14, 15, 16, 17, 48, 52, 55, 60, 63, 66, 70, 73], "dataset_nam": [2, 5, 14, 48, 52, 55, 60, 63, 66, 70, 73, 92, 94], "set_dataset": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 66], "creat": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 26, 34, 40, 41, 42, 43, 44, 45, 46, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 66, 67, 69, 70, 72, 73, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92], "wb": [2, 5], "whisperbenchmark": [2, 5, 94], "run": [2, 4, 5, 66, 70, 94], "convert": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 50, 54, 57, 62, 65, 67, 69, 72, 75, 77], "metric": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 50, 54, 57, 62, 65, 69, 72, 75, 77, 90, 91, 92, 94], "panda": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 92], "datafram": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 26, 30, 35, 40, 41, 42, 43, 44, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92], "df": [2, 5, 17, 19, 40, 41, 42, 43, 44, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92], "convert_to_panda": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13], "print": [2, 5, 14, 31, 45, 97], "save": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 19, 20, 22, 33, 34, 40, 41, 42, 43, 44, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92], "csv": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 20, 26], "datetim": [2, 5, 21], "benchmark_results_to_csv": [2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13], "5": [2, 45], "benchmark_dataset": [2, 4], "dataset_rdh": 2, "benchmark_class_list": [2, 4, 94], "list": [2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 26, 30, 35, 46, 50, 54, 57, 62, 65, 66, 69, 72, 75, 77, 92, 94], "whisperapibenchmark": [2, 94], "result": [2, 19, 20, 26, 30, 35, 41, 42, 43, 44, 50, 54, 66, 87, 92, 94], "run_benchmark": [2, 94], "function": [2, 40, 48, 67, 79, 83, 94], "class": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 32, 40, 41, 42, 43, 44, 45, 46, 48, 49, 50, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94], "with_clean": [3, 6, 7, 8, 9, 10, 11, 12, 13, 46, 50, 54, 57, 62, 65, 69, 72, 75, 77], "true": [3, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 30, 46, 50, 54, 57, 62, 65, 69, 72, 75, 77], "sourc": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 23, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 41, 42, 43, 44, 45, 46, 49, 50, 51, 53, 54, 56, 57, 58, 59, 61, 62, 64, 65, 67, 68, 69, 71, 72, 74, 75, 76, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92], "base": [3, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 41, 42, 43, 44, 46, 49, 50, 53, 54, 56, 57, 61, 62, 64, 65, 67, 68, 69, 71, 72, 74, 75, 76, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92], "abc": [3, 19, 69], "i": [3, 14, 25, 38, 45, 46, 49, 70, 80, 81, 82, 84, 85, 86, 90, 91, 92, 94, 97], "test": [3, 97], "valid": [3, 15, 16, 17], "an": [3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 25, 46, 50, 54, 57, 58, 62, 65, 69, 72, 75, 77, 80, 81, 82, 84, 85, 86, 92, 94, 97], "model": [3, 6, 7, 8, 9, 10, 11, 12, 13, 35, 40, 45, 46, 79, 83, 97], "parent": [3, 19, 34, 66, 88, 89, 90, 91], "all": [3, 15, 16, 17, 30, 35, 46, 87, 92], "object": [3, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 41, 42, 43, 44, 46, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92], "paramet": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 26, 28, 29, 30, 31, 33, 34, 35, 36, 38, 41, 42, 43, 44, 46, 49, 50, 51, 53, 54, 57, 58, 59, 61, 62, 64, 65, 68, 69, 71, 72, 74, 75, 76, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92], "bool": [3, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 30, 46, 50, 54, 57, 62, 65, 69, 72, 75, 77], "option": [3, 6, 7, 8, 9, 10, 11, 12, 13, 26, 30, 33, 46, 50, 54, 57, 62, 65, 69, 72, 75, 77], "clean": [3, 6, 7, 8, 9, 10, 11, 12, 13, 18, 24, 36, 46, 50, 54, 57, 62, 65, 69, 72, 75, 77], "default": [3, 6, 7, 8, 9, 10, 11, 12, 13, 20, 21, 22, 26, 30, 33, 44, 46, 49, 50, 53, 54, 56, 57, 61, 62, 64, 65, 69, 71, 72, 75, 77], "method": [3, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 32, 41, 42, 43, 44, 46, 50, 54, 57, 62, 65, 67, 69, 72, 75, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92], "attribut": [3, 6, 7, 8, 9, 10, 11, 12, 13, 18, 49, 50, 53, 54, 56, 57, 61, 62, 64, 65, 69, 71, 72, 74, 75, 76, 77, 92], "benchmark_sampl": [3, 6, 7, 8, 9, 10, 11, 12, 13, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 69, 70, 72, 73, 75, 77], "none": [3, 6, 7, 8, 9, 10, 11, 12, 13], "sampl": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 67, 69, 70, 72, 73, 75, 77], "type": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 20, 21, 22, 24, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 41, 42, 43, 44, 46, 50, 54, 56, 57, 62, 65, 67, 69, 72, 75, 77, 80, 81, 82, 85, 86, 88, 89, 92], "origin": [3, 6, 7, 8, 9, 10, 11, 12, 13, 45, 50, 54, 57, 62, 65, 69, 72, 75, 77], "error_list": [3, 6, 7, 8, 9, 10, 11, 12, 13, 94], "error": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 43, 46, 50, 54, 57, 58, 59, 62, 65, 69, 70, 72, 75, 77, 79, 80, 81, 82, 87, 92, 94], "pd": [3, 6, 7, 8, 9, 10, 11, 12, 13, 19, 26, 30, 35, 40, 41, 42, 43, 44, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92], "core": [3, 6, 7, 8, 9, 10, 11, 12, 13, 19, 26, 30, 35, 40, 41, 42, 43, 44, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92], "frame": [3, 6, 7, 8, 9, 10, 11, 12, 13, 19, 26, 30, 35, 40, 41, 42, 43, 44, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92], "__call__": [3, 6, 7, 8, 9, 10, 11, 12, 13, 46, 67], "n": [3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 69, 70, 72, 73, 75, 77], "int": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 46, 50, 54, 57, 62, 65, 69, 72, 75, 77], "number": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 46, 50, 54, 57, 62, 65, 69, 72, 75, 77], "transcript": [3, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 23, 24, 46, 50, 51, 54, 57, 62, 65, 69, 72, 75, 77, 94, 97], "return": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 23, 28, 29, 30, 31, 33, 34, 35, 36, 38, 40, 41, 42, 43, 44, 46, 50, 54, 57, 62, 65, 66, 67, 69, 72, 75, 77, 79, 80, 81, 82, 83, 85, 86, 88, 89, 94, 97], "abstract": [3, 19, 41, 69, 88, 89, 91], "create_model": [3, 6, 7, 8, 9, 10, 11, 12, 13, 66, 94], "modelwrapp": [3, 6, 7, 8, 9, 10, 11, 12, 13, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 70, 72, 73, 75, 77], "wrapper": [3, 6, 7, 8, 9, 10, 11, 12, 13, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 66, 67, 69, 70, 72, 73, 75, 77], "save_to_csv": [3, 6, 7, 8, 9, 10, 11, 12, 13], "save_nam": [3, 6, 7, 8, 9, 10, 11, 12, 13, 26], "output": [3, 6, 7, 8, 9, 10, 11, 12, 13, 26, 46], "str": [3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 21, 22, 24, 26, 28, 29, 31, 33, 34, 36, 38, 41, 42, 43, 44, 46, 50, 51, 54, 57, 58, 59, 62, 65, 66, 69, 72, 75, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92, 94], "filenam": [3, 6, 7, 8, 9, 10, 11, 12, 13, 26], "classmethod": [3, 6, 7, 8, 9, 10, 11, 12, 13], "update_sampl": [3, 6, 7, 8, 9, 10, 11, 12, 13], "cl": [3, 6, 7, 8, 9, 10, 11, 12, 13, 67], "updat": [3, 6, 7, 8, 9, 10, 11, 12, 13], "al": 4, "out": 4, "benchmark_list": 4, "To": [4, 94], "amazon": [6, 48, 49, 50], "api": [6, 7, 8, 9, 10, 11, 12, 23, 48, 49, 50, 52, 53, 54, 55, 56, 57, 60, 61, 62, 63, 64, 65, 70, 71, 72, 73, 74, 75, 94], "transcrib": [6, 10, 46, 50, 51, 54, 57, 62, 65, 66, 67, 72, 94], "model_bas": [6, 7, 8, 9, 10, 11, 12, 13, 66, 94], "amazonapi": [6, 49], "assemblyai": [7, 52, 53, 54], "assemblyaiapi": 7, "azur": [8, 55, 56, 57, 58, 59], "azureapi": [8, 56], "deepgram": [9, 60, 61, 62], "deepgramapi": 9, "googl": [10, 63, 64, 65], "googleapi": [10, 64], "speechmat": [11, 70, 71, 72], "speechmaticsapi": [11, 71], "whisper": [12, 13, 49, 53, 56, 61, 64, 69, 73, 74, 75, 76, 77], "whisperapi": 12, "local": [13, 73], "packag": [14, 18, 70, 94, 97], "The": [14, 46, 87, 90, 91, 94], "requir": [14, 25, 95], "txt": [14, 15, 16, 17, 97], "folder": [14, 15, 19, 22, 33, 34, 41, 42, 43, 44, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 97], "In": 14, "ar": [14, 87], "rel": 14, "link": [14, 97], "audiofil": [14, 46], "follow": [14, 94, 97], "file": [14, 15, 16, 17, 19, 28, 29, 41, 42, 43, 44, 46, 50, 54, 57, 62, 65, 69, 70, 72, 75, 77, 92, 94, 97], "exampl": [14, 95], "entri": 14, "20000_mijlen": 14, "20000_mijlen_0001": 14, "wav": [14, 15, 16, 17, 50, 54, 57, 62, 65, 69, 72, 75, 77], "trancsript": 14, "audio": [14, 46, 50, 54, 57, 62, 65, 69, 72, 75, 77, 94], "benchmark": [14, 20, 26, 30, 35, 42, 43, 44, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 66, 69, 70, 72, 73, 75, 77, 80, 81, 82, 84, 85, 86, 87, 92], "id": [14, 15, 16, 17, 46, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 69, 70, 72, 73, 75, 77, 97], "existing_id": 14, "get": [14, 15, 16, 17, 28, 29, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 69, 70, 72, 73, 75, 77, 94], "get_path_of_frag": [14, 15, 16, 17], "get_text_of_id": [14, 15, 16, 17], "trandom": 14, "dataset_n_random": 14, "sampledataset": [14, 15, 50, 54, 57, 62, 65, 69, 72, 75, 77], "get_n_sampl": [14, 15], "file_ext": [15, 16, 17, 50], "datasetbar": [15, 17], "extract": 15, "data": [15, 54, 79, 83, 92], "There": [15, 16, 17], "need": [15, 16, 17, 19, 41, 42, 43, 44, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 66, 69, 70, 72, 73, 75, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92, 94], "directli": [15, 16, 17], "param": [15, 16, 17, 56], "end": [15, 16, 17], "extent": [15, 16, 17, 28, 29, 50], "random": [15, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 69, 70, 72, 73, 75, 77], "audio_id": [15, 16, 17, 30, 46, 50, 54, 57, 62, 65, 69, 72, 75, 77], "fragment": [15, 16, 17], "rais": [15, 16, 17, 31, 50], "filenotfounderror": [15, 16, 17], "If": [15, 16, 17, 67, 69], "doesn": [15, 16, 17], "t": [15, 16, 17], "exist": [15, 16, 17, 50], "text": [15, 16, 17, 36, 45, 66, 92, 94], "string": [15, 16, 17, 18, 21, 36, 38, 54], "spoken": [15, 16, 17], "load_transcript": 15, "load": [15, 31, 94], "validate_sampl": [15, 16, 17], "have": [15, 16, 17, 94], "correspond": [15, 16, 17], "bare": 16, "forc": [18, 27, 94], "torch": [18, 27], "cuda": [18, 27], "force_cudnn_initi": [18, 94], "string_clean": 18, "ha": [18, 67], "8": 18, "except": [18, 23, 25, 50, 55, 58, 59], "report_fold": [19, 41, 42, 43, 44, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91], "file_nam": [19, 28, 29, 41, 42, 43, 44, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91], "child": [19, 41, 42, 43, 44, 66, 88, 89, 90, 91], "should": [19, 41, 42, 43, 44, 88, 89, 90, 91], "made": [19, 46, 88, 89, 94], "ad": [19, 41, 42, 43, 44, 46, 87, 88, 89, 90, 91], "plot": [19, 40, 41, 42, 43, 44, 73, 94], "custom_result": [19, 40, 41, 42, 43, 44, 87, 88, 89, 92], "custom_error": [19, 79, 87, 88, 89, 92], "custom_plot": [19, 83, 87, 88, 89, 90, 91, 92], "custom_error_plot": [19, 87, 88, 89, 92], "benchmark_results_2023_06_01_10_05_26": [], "2023_06_01_10_05_26": [], "format": [21, 50, 54, 57, 62, 65, 69, 72, 75, 77], "when": [23, 25, 50, 58, 59], "doe": [23, 50], "A": 24, "za": 24, "z0": 24, "9": [24, 96], "regex": 24, "env_nam": [25, 31], "env": [25, 31, 48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 70, 72, 73, 75, 94], "variabl": [25, 31], "miss": [25, 31], "default_csv_nam": 26, "avail": [27, 49, 53, 56, 61, 64, 68, 71, 74, 76], "tile": [28, 29], "set_index": 30, "join": 30, "model_nam": [30, 66, 79, 83], "can": [30, 88, 89], "index": [30, 95], "kei": [31, 97], "requiredenvvariablesmiss": 31, "its": 31, "valu": [31, 49, 53, 56, 61, 64, 68, 71, 74, 76], "allow": 32, "overload": 32, "folder_nam": 33, "make": [33, 54], "default_report_fold": 33, "folder_path": 34, "subfolder_nam": 34, "subfold": 34, "seper": 35, "each": [35, 50, 54, 57, 62, 65, 69, 72, 75, 77, 90, 91], "stt": [36, 48, 50, 54, 55, 57, 62, 63, 65, 70, 72], "unclean": 36, "f": [37, 46], "durat": [37, 45, 46], "where": 38, "first": 38, "charact": [38, 46], "uppercas": 38, "process": 38, "custom": [40, 49, 79, 83, 87, 88, 89], "baseresult": [40, 41, 42, 43, 44, 79, 83, 88, 89, 90, 91, 92], "matplotlib": [40, 79, 83, 88, 92], "pictur": [40, 79, 83], "benchmarkresult": [40, 92], "basemetr": [40, 42, 43, 44], "def": [40, 66, 79, 83, 94], "create_df": [40, 41, 42, 43, 44], "self": [40, 66, 67, 69, 79, 83, 94], "add": [40, 73, 79, 83], "append": [40, 50, 54, 57, 62, 65, 66, 69, 72, 75, 77, 79, 83, 94], "calul": [43, 44, 46], "statist": [43, 44], "calcul": [45, 46], "m": 45, "hypothesi": [45, 46], "id_from_dataset": 45, "0": [45, 70], "refer": 46, "wer": [46, 79, 83], "word": 46, "rate": 46, "how": [46, 94], "mani": 46, "were": [46, 92], "float": 46, "mer": 46, "match": [46, 59], "indic": 46, "percentag": 46, "incorrectli": 46, "predict": 46, "insert": 46, "wil": 46, "inform": 46, "lost": 46, "repres": [46, 50], "wip": 46, "preserv": 46, "cer": 46, "substitut": 46, "replac": 46, "hit": 46, "correct": [46, 50, 54, 57, 62, 65, 69, 72, 75, 77, 94], "correctli": 46, "delet": [46, 51], "remov": 46, "long": 46, "took": 46, "meteor": 46, "evalu": 46, "translat": [46, 54], "explicit": 46, "order": [46, 67], "automat": 46, "machin": 46, "gener": [46, 54, 61, 88, 89], "concept": 46, "unigram": 46, "between": 46, "produc": 46, "human": 46, "bleu": 46, "bilingu": 46, "understudi": 46, "compar": 46, "candid": 46, "one": 46, "more": 46, "rouge_1_r": 46, "recal": 46, "orient": 46, "gist": 46, "1": [46, 54, 70, 74], "gram": 46, "roug": 46, "r": 46, "includ": 46, "measur": 46, "determin": 46, "qualiti": 46, "summari": 46, "other": 46, "ideal": 46, "rouge_1_p": 46, "precis": 46, "p": 46, "rouge_1_f": 46, "f1": 46, "score": 46, "rouge_2_r": 46, "2": [46, 96, 97], "rouge_2_p": 46, "rouge_2_f": 46, "rouge_l_r": 46, "lc": 46, "l": 46, "longest": 46, "common": 46, "subsequ": 46, "our": 46, "rouge_l_p": 46, "rouge_l_f": 46, "arg": [46, 67], "kwd": 46, "get_all_metric_doc": 46, "descript": 46, "get_all_metric_nam": 46, "possibl": 46, "implement": [48, 52, 55, 60, 63, 66, 70, 73], "aws_access_key_id": [48, 50, 97], "aws_secret_access_kei": [48, 50, 97], "amazon_region": [48, 50, 97], "amazon_bucket": [48, 50, 97], "existing_audio_id": [48, 52, 55, 60, 63, 70, 73], "amazonapivers": [48, 50], "amazon_default": [48, 49], "get_model": [48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 66, 69, 70, 72, 73, 75, 77, 94], "choisen": [48, 52, 55, 60, 63, 70, 73], "arrai": [48, 52, 55, 60, 63, 70, 73], "benchmark_n_sampl": [48, 50, 52, 54, 55, 57, 60, 62, 63, 65, 69, 70, 72, 73, 75, 77], "modelvers": [49, 53, 56, 61, 64, 66, 71, 74, 76, 94], "enum": [49, 53, 56, 61, 64, 68, 71, 74, 76], "languag": [49, 50, 54, 57, 62, 65, 72], "version": [49, 50, 53, 54, 56, 57, 61, 62, 64, 65, 66, 69, 70, 71, 72, 74, 75, 76, 77, 94], "model_vers": [50, 54, 57, 62, 65, 66, 69, 72, 75, 77, 94], "current": [50, 54, 57, 62, 65, 70, 72, 75], "directori": [50, 54, 57, 62, 65, 70, 72, 75, 87, 97], "bucket_exist": 50, "boolean": 50, "bucket": [50, 97], "language_cod": [50, 54, 57, 62, 65, 72, 94], "nl": [50, 54, 57, 62, 65, 72, 94], "code": [50, 54, 57, 62, 65, 72, 88, 89, 95], "see": [50, 54, 57, 62, 65, 72], "support": [50, 54, 57, 62, 65, 72], "path_of_temp_converted_audio_fil": [50, 54, 57, 62, 65, 69, 72, 75, 77], "converted_audio_fil": [50, 54, 57, 62, 65, 69, 72, 75, 77], "temp": [50, 54, 57, 62, 65, 69, 72, 75, 77], "accept": [50, 54, 57, 62, 65, 69, 72, 75, 77], "_append_error": [50, 54, 57, 62, 65, 69, 72, 75, 77], "model_error": [50, 54, 57, 62, 65, 69, 72, 75, 77], "fail": [50, 54, 57, 62, 65, 69, 72, 75, 77], "messag": [50, 54, 57, 58, 59, 62, 65, 69, 72, 75, 77], "_benchmark_sample_with_tim": [50, 54, 57, 62, 65, 69, 72, 75, 77], "timer": [50, 54, 57, 62, 65, 69, 72, 75, 77], "_get_transcribe_file_loc": 50, "file_uri": 50, "transcribe_cli": [50, 51], "job_nam": [50, 51], "locat": 50, "amazonnotranscriptreturn": 50, "s3": [50, 97], "boto3": [50, 51], "client": [50, 51], "aw": 50, "job": [50, 51], "_get_transcript_from_json_uri": 50, "json_uri": 50, "json": [50, 97], "uri": 50, "benchmerk": [50, 54, 57, 62, 65, 69, 72, 75, 77], "convert_sampl": [50, 54, 57, 62, 65, 69, 72, 75, 77], "path_to_sampl": [50, 54, 57, 62, 65, 69, 72, 75, 77], "overrid": [50, 54, 57, 62, 65, 69, 72, 75, 77], "fals": [50, 54, 57, 62, 65, 69, 72, 75, 77], "also": 51, "associ": 51, "botocor": 51, "transcribeservic": 51, "assembly_ai_api_kei": [52, 54, 97], "assemblyaiapivers": [52, 54], "assemblyai_default": [52, 53], "api_url": 54, "http": 54, "com": [54, 72, 97], "v2": [54, 72], "upload": 54, "connect": [54, 72], "url": [54, 72], "polling_endpoint": 54, "poll": 54, "endpoint": 54, "time_sleep": 54, "3": [54, 96, 97], "time": 54, "sleep": 54, "after": 54, "transcript_endpoint": 54, "upload_endpoint": 54, "_clean_output": 54, "paragraph": 54, "_get_paragraph": 54, "header": 54, "dict": 54, "_make_polling_endpoint": 54, "transcript_respons": 54, "endoint": 54, "respons": 54, "_read_file_with_chunck_s": 54, "audio_file_nam": [54, 66, 94], "chunk_siz": 54, "5242880": 54, "read": 54, "size": 54, "chunk": 54, "yield": 54, "_request_transcript": 54, "upload_url": 54, "request": 54, "_upload_fil": 54, "_wait_for_complet": 54, "wait": 54, "done": 54, "azure_speech_kei": [55, 57, 97], "azure_speech_region": [55, 57, 97], "azureapivers": [55, 57], "azure_default": [55, 56], "BE": [57, 65], "give": 58, "cancel": 58, "_summary_": [58, 59], "find": 59, "deepgram_api_kei": [60, 62, 97], "deepgramapivers": [60, 62], "deepgram_default": [60, 61], "deepgram_enhanc": 61, "enhanc": [61, 94], "google_application_credenti": [63, 65, 97], "googleapivers": [63, 65], "google_default": [63, 64], "modulewrapp": 66, "childmodelvers": 66, "demo": 66, "childmodelwrapp": 66, "__init__": [66, 94], "modeltyp": 66, "get_transcript_of_fil": [66, 67, 69, 94], "childbenchmark": 66, "attr": 67, "meta": 67, "automaticli": 67, "befor": [67, 94], "wrap": 67, "kwarg": 67, "call": [67, 94], "static": 67, "__new__": 67, "mro": 67, "": 67, "resolut": 67, "instanc": 67, "whispermodel": 69, "python": [70, 96, 97], "6": 70, "4": 70, "script": [70, 97], "7": 70, "speechmatics_api_kei": [70, 72, 97], "speechmaticsapivers": [70, 72], "speechmatics_default": [70, 71], "connection_url": 72, "wss": 72, "eu2": 72, "rt": 72, "openai_api_kei": [73, 75, 97], "openai_organ": [73, 75, 97], "whispervers": [73, 77], "tini": [73, 76], "whisper_1": 74, "onlin": 74, "larg": 76, "biggest": 76, "medium": 76, "larger": 76, "small": 76, "second": 76, "smallest": 76, "boxplotofmodelsw": [79, 83], "baseplot": [79, 80, 81, 82, 83, 86, 87, 88, 89], "create_plot": [79, 80, 81, 82, 83, 85, 86, 88, 89, 91], "figur": [79, 80, 81, 82, 83, 85, 86, 88, 89], "sn": [79, 83], "boxplot": [79, 83], "x": [79, 83, 97], "y": [79, 83], "fig": [79, 83], "get_figur": [79, 83], "save_plot": [79, 83], "savefig": [79, 83], "save_file_nam": [79, 83], "plotli": [79, 80, 81, 82, 83, 86, 88, 89, 92], "demoplotlyexampl": [79, 83], "graph_obj": [79, 80, 81, 82, 83, 86, 88, 89], "_figur": [79, 80, 81, 82, 83, 86, 88, 89], "px": [79, 83], "gapmind": [79, 83], "queri": [79, 83], "countri": [79, 83], "canada": [79, 83], "line": [79, 83], "year": [79, 83], "lifeexp": [79, 83], "titl": [79, 83], "life": [79, 83], "expect": [79, 83], "baseplotli": [80, 81, 82], "dynamicplotclassesbymetricbydataset": 84, "create_plot_class": [84, 85, 90, 91], "dynamicplotclassesbymetricforeachdataset": 85, "basematplotlib": 86, "plot_nam": [86, 88], "error_plot": 87, "save_al": [87, 92, 94], "d": [88, 89], "tale": [88, 89], "dynam": [90, 91], "databas": 90, "given": [90, 91], "could": 92, "customerrorplot": 92, "errorcountbymodel": 92, "errorcountbymodelbydataset": 92, "errorcountheatmap": 92, "anoth": 92, "customplot": 92, "dynamicallybymodelnameforeachdataset": 92, "dynamicallybymodelnamebydataset": 92, "metricheatmap": 92, "custommetr": [92, 94], "resultmetr": 92, "launch_dtal": 92, "launch": 92, "webui": 92, "explor": 92, "loop": 92, "over": 92, "page": [94, 95], "collect": 94, "might": 94, "dotenv": 94, "load_dotenv": 94, "custombenchmark": 94, "100": 94, "benchmark_nam": 94, "load_env_vari": 94, "custommodelvers": 94, "model_version_1": 94, "version_1": 94, "model_version_2": 94, "version_2": 94, "model_version_enhanc": 94, "custommodelwrapp": 94, "super": 94, "setup": 94, "api_kei": 94, "model_api_kei": 94, "custommodelbenchmark": 94, "instal": 95, "search": 95, "sample_env": 96, "channel": 96, "depend": 96, "11": 96, "sk": 97, "somemorerandomnumberlettersandmorerandomnessform": 97, "org": 97, "somerandomnumberandlett": 97, "access": 97, "acc": 97, "eu": 97, "west": 97, "For": 97, "foo": 97, "command": 97, "region": 97, "curl": 97, "si": 97, "amazonaw": 97, "awk": 97, "amz": 97, "servic": 97, "account": 97, "cloud": 97, "doc": 97, "keyfil": 97, "benchmark_results_2023_06_01_12_09_25": [], "2023_06_01_12_09_25": [], "benchmark_results_2023_06_01_13_01_32": [20, 26], "2023_06_01_13_01_32": 21}, "objects": {"": [[0, 0, 0, "-", "speechtotext"]], "speechtotext": [[1, 0, 0, "-", "benchmark"], [14, 0, 0, "-", "datasets"], [18, 0, 0, "-", "functions"], [39, 0, 0, "-", "metric"], [47, 0, 0, "-", "model"], [78, 0, 0, "-", "plot"]], "speechtotext.benchmark": [[2, 0, 0, "-", "benchmarks"], [5, 0, 0, "-", "customBenchmarks"]], "speechtotext.benchmark.benchmarks": [[3, 1, 1, "", "Benchmark"], [4, 4, 1, "", "run_benchmarks"]], "speechtotext.benchmark.benchmarks.Benchmark": [[3, 2, 1, "", "BENCHMARK_SAMPLES"], [3, 2, 1, "", "DATASET"], [3, 2, 1, "", "ERROR_LIST"], [3, 3, 1, "", "__call__"], [3, 3, 1, "", "convert_to_pandas"], [3, 3, 1, "", "create_models"], [3, 3, 1, "", "save_to_csv"], [3, 3, 1, "", "set_dataset"], [3, 3, 1, "", "update_samples"]], "speechtotext.benchmark.customBenchmarks": [[6, 1, 1, "", "AmazonAPIBenchmark"], [7, 1, 1, "", "AssemblyAIAPIBenchmark"], [8, 1, 1, "", "AzureAPIBenchmark"], [9, 1, 1, "", "DeepgramAPIBenchmark"], [10, 1, 1, "", "GoogleAPIBenchmark"], [11, 1, 1, "", "SpeechmaticsAPIBenchmark"], [12, 1, 1, "", "WhisperAPIBenchmark"], [13, 1, 1, "", "WhisperBenchmark"]], "speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark": [[6, 2, 1, "", "BENCHMARK_SAMPLES"], [6, 2, 1, "", "DATASET"], [6, 2, 1, "", "ERROR_LIST"], [6, 2, 1, "", "MODEL_BASE"], [6, 3, 1, "", "__call__"], [6, 3, 1, "", "convert_to_pandas"], [6, 3, 1, "", "create_models"], [6, 3, 1, "", "save_to_csv"], [6, 3, 1, "", "set_dataset"], [6, 3, 1, "", "update_samples"]], "speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark": [[7, 2, 1, "", "BENCHMARK_SAMPLES"], [7, 2, 1, "", "DATASET"], [7, 2, 1, "", "ERROR_LIST"], [7, 2, 1, "", "MODEL_BASE"], [7, 3, 1, "", "__call__"], [7, 3, 1, "", "convert_to_pandas"], [7, 3, 1, "", "create_models"], [7, 3, 1, "", "save_to_csv"], [7, 3, 1, "", "set_dataset"], [7, 3, 1, "", "update_samples"]], "speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark": [[8, 2, 1, "", "BENCHMARK_SAMPLES"], [8, 2, 1, "", "DATASET"], [8, 2, 1, "", "ERROR_LIST"], [8, 2, 1, "", "MODEL_BASE"], [8, 3, 1, "", "__call__"], [8, 3, 1, "", "convert_to_pandas"], [8, 3, 1, "", "create_models"], [8, 3, 1, "", "save_to_csv"], [8, 3, 1, "", "set_dataset"], [8, 3, 1, "", "update_samples"]], "speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark": [[9, 2, 1, "", "BENCHMARK_SAMPLES"], [9, 2, 1, "", "DATASET"], [9, 2, 1, "", "ERROR_LIST"], [9, 2, 1, "", "MODEL_BASE"], [9, 3, 1, "", "__call__"], [9, 3, 1, "", "convert_to_pandas"], [9, 3, 1, "", "create_models"], [9, 3, 1, "", "save_to_csv"], [9, 3, 1, "", "set_dataset"], [9, 3, 1, "", "update_samples"]], "speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark": [[10, 2, 1, "", "BENCHMARK_SAMPLES"], [10, 2, 1, "", "DATASET"], [10, 2, 1, "", "ERROR_LIST"], [10, 2, 1, "", "MODEL_BASE"], [10, 3, 1, "", "__call__"], [10, 3, 1, "", "convert_to_pandas"], [10, 3, 1, "", "create_models"], [10, 3, 1, "", "save_to_csv"], [10, 3, 1, "", "set_dataset"], [10, 3, 1, "", "update_samples"]], "speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark": [[11, 2, 1, "", "BENCHMARK_SAMPLES"], [11, 2, 1, "", "DATASET"], [11, 2, 1, "", "ERROR_LIST"], [11, 2, 1, "", "MODEL_BASE"], [11, 3, 1, "", "__call__"], [11, 3, 1, "", "convert_to_pandas"], [11, 3, 1, "", "create_models"], [11, 3, 1, "", "save_to_csv"], [11, 3, 1, "", "set_dataset"], [11, 3, 1, "", "update_samples"]], "speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark": [[12, 2, 1, "", "BENCHMARK_SAMPLES"], [12, 2, 1, "", "DATASET"], [12, 2, 1, "", "ERROR_LIST"], [12, 2, 1, "", "MODEL_BASE"], [12, 3, 1, "", "__call__"], [12, 3, 1, "", "convert_to_pandas"], [12, 3, 1, "", "create_models"], [12, 3, 1, "", "save_to_csv"], [12, 3, 1, "", "set_dataset"], [12, 3, 1, "", "update_samples"]], "speechtotext.benchmark.customBenchmarks.WhisperBenchmark": [[13, 2, 1, "", "BENCHMARK_SAMPLES"], [13, 2, 1, "", "DATASET"], [13, 2, 1, "", "ERROR_LIST"], [13, 2, 1, "", "MODEL_BASE"], [13, 3, 1, "", "__call__"], [13, 3, 1, "", "convert_to_pandas"], [13, 3, 1, "", "create_models"], [13, 3, 1, "", "save_to_csv"], [13, 3, 1, "", "set_dataset"], [13, 3, 1, "", "update_samples"]], "speechtotext.datasets": [[15, 1, 1, "", "Dataset"], [16, 1, 1, "", "DatasetBare"], [17, 1, 1, "", "SampleDataset"]], "speechtotext.datasets.Dataset": [[15, 3, 1, "", "get_n_samples"], [15, 3, 1, "", "get_path_of_fragment"], [15, 3, 1, "", "get_text_of_id"], [15, 3, 1, "", "load_transcript"], [15, 3, 1, "", "number_of_samples"], [15, 3, 1, "", "validate_samples"]], "speechtotext.datasets.DatasetBare": [[16, 3, 1, "", "get_path_of_fragment"], [16, 3, 1, "", "get_text_of_id"], [16, 3, 1, "", "number_of_samples"], [16, 3, 1, "", "validate_samples"]], "speechtotext.datasets.SampleDataset": [[17, 3, 1, "", "get_path_of_fragment"], [17, 3, 1, "", "get_text_of_id"], [17, 3, 1, "", "number_of_samples"], [17, 3, 1, "", "validate_samples"]], "speechtotext.functions": [[19, 1, 1, "", "BaseResult"], [20, 5, 1, "", "DEFAULT_CSV_NAME"], [21, 5, 1, "", "DEFAULT_DATETIME_FORMAT"], [22, 5, 1, "", "DEFAULT_REPORTS_FOLDER"], [23, 6, 1, "", "NoTranscriptReturned"], [24, 5, 1, "", "REGEX_STRING_PARSE"], [25, 6, 1, "", "RequiredEnvVariablesMissing"], [26, 4, 1, "", "benchmark_results_to_csv"], [27, 4, 1, "", "force_cudnn_initialization"], [28, 4, 1, "", "get_extention_of_file_name"], [29, 4, 1, "", "get_file_name_without_extention"], [30, 4, 1, "", "join_benchmark_results"], [31, 4, 1, "", "load_env_variable"], [32, 4, 1, "", "multidispatch"], [33, 4, 1, "", "save_folder_name"], [34, 4, 1, "", "save_sub_folder_name"], [35, 4, 1, "", "separate_benchmark_results_by_model"], [36, 4, 1, "", "string_cleaning"], [37, 4, 1, "", "timing"], [38, 4, 1, "", "uppercase_for_first_character_in_string"]], "speechtotext.functions.BaseResult": [[19, 3, 1, "", "save"]], "speechtotext.metric": [[40, 0, 0, "-", "customMetrics"], [45, 0, 0, "-", "metrics"]], "speechtotext.metric.customMetrics": [[41, 1, 1, "", "BaseMetrics"], [42, 1, 1, "", "BenchmarkResults"], [43, 1, 1, "", "ErrorMetrics"], [44, 1, 1, "", "ResultMetrics"]], "speechtotext.metric.customMetrics.BaseMetrics": [[41, 3, 1, "", "create_df"], [41, 3, 1, "", "save"]], "speechtotext.metric.customMetrics.BenchmarkResults": [[42, 3, 1, "", "create_df"], [42, 3, 1, "", "save"]], "speechtotext.metric.customMetrics.ErrorMetrics": [[43, 3, 1, "", "create_df"], [43, 3, 1, "", "save"]], "speechtotext.metric.customMetrics.ResultMetrics": [[44, 3, 1, "", "create_df"], [44, 3, 1, "", "save"]], "speechtotext.metric.metrics": [[46, 1, 1, "", "Metrics"]], "speechtotext.metric.metrics.Metrics": [[46, 3, 1, "", "__call__"], [46, 2, 1, "", "bleu"], [46, 2, 1, "", "cer"], [46, 2, 1, "", "deletions"], [46, 2, 1, "", "duration"], [46, 3, 1, "", "get_all_metric_docs"], [46, 3, 1, "", "get_all_metric_names"], [46, 2, 1, "", "hits"], [46, 2, 1, "", "insertions"], [46, 2, 1, "", "mer"], [46, 2, 1, "", "meteor"], [46, 2, 1, "", "rouge_1_f"], [46, 2, 1, "", "rouge_1_p"], [46, 2, 1, "", "rouge_1_r"], [46, 2, 1, "", "rouge_2_f"], [46, 2, 1, "", "rouge_2_p"], [46, 2, 1, "", "rouge_2_r"], [46, 2, 1, "", "rouge_l_f"], [46, 2, 1, "", "rouge_l_p"], [46, 2, 1, "", "rouge_l_r"], [46, 2, 1, "", "substitutions"], [46, 2, 1, "", "wer"], [46, 2, 1, "", "wil"], [46, 2, 1, "", "wip"]], "speechtotext.model": [[48, 0, 0, "-", "amazonWrapper"], [52, 0, 0, "-", "assemblyAIWrapper"], [55, 0, 0, "-", "azureWrapper"], [60, 0, 0, "-", "deepgramWrapper"], [63, 0, 0, "-", "googleWrapper"], [66, 0, 0, "-", "modelWrapper"], [70, 0, 0, "-", "speechmaticsWrapper"], [73, 0, 0, "-", "whisperWrapper"]], "speechtotext.model.amazonWrapper": [[49, 1, 1, "", "AmazonAPIVersion"], [50, 1, 1, "", "AmazonAPIWrapper"], [51, 4, 1, "", "amazon_delete_job"]], "speechtotext.model.amazonWrapper.AmazonAPIVersion": [[49, 2, 1, "", "AMAZON_DEFAULT"]], "speechtotext.model.amazonWrapper.AmazonAPIWrapper": [[50, 2, 1, "", "BUCKET_EXIST"], [50, 2, 1, "", "LANGUAGE_CODE"], [50, 2, 1, "", "PATH_OF_TEMP_CONVERTED_AUDIO_FILE"], [50, 3, 1, "", "_append_error"], [50, 3, 1, "", "_benchmark_sample_with_time"], [50, 3, 1, "", "_get_transcribe_file_location"], [50, 3, 1, "", "_get_transcript_from_json_uri"], [50, 3, 1, "", "benchmark_n_samples"], [50, 3, 1, "", "benchmark_sample"], [50, 3, 1, "", "benchmark_samples"], [50, 3, 1, "", "convert_sample"], [50, 3, 1, "", "get_model"]], "speechtotext.model.assemblyAIWrapper": [[53, 1, 1, "", "AssemblyAIAPIVersion"], [54, 1, 1, "", "AssemblyAIAPIWrapper"]], "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIVersion": [[53, 2, 1, "", "ASSEMBLYAI_DEFAULT"]], "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper": [[54, 2, 1, "", "API_URL"], [54, 2, 1, "", "LANGUAGE_CODE"], [54, 2, 1, "", "PATH_OF_TEMP_CONVERTED_AUDIO_FILE"], [54, 2, 1, "", "POLLING_ENDPOINT"], [54, 2, 1, "", "TIME_SLEEP"], [54, 2, 1, "", "TRANSCRIPT_ENDPOINT"], [54, 2, 1, "", "UPLOAD_ENDPOINT"], [54, 3, 1, "", "_append_error"], [54, 3, 1, "", "_benchmark_sample_with_time"], [54, 3, 1, "", "_clean_output"], [54, 3, 1, "", "_get_paragraphs"], [54, 3, 1, "", "_make_polling_endpoint"], [54, 3, 1, "", "_read_file_with_chunck_size"], [54, 3, 1, "", "_request_transcript"], [54, 3, 1, "", "_upload_file"], [54, 3, 1, "", "_wait_for_completion"], [54, 3, 1, "", "benchmark_n_samples"], [54, 3, 1, "", "benchmark_sample"], [54, 3, 1, "", "benchmark_samples"], [54, 3, 1, "", "convert_sample"], [54, 3, 1, "", "get_model"]], "speechtotext.model.azureWrapper": [[56, 1, 1, "", "AzureAPIVersion"], [57, 1, 1, "", "AzureAPIWrapper"], [58, 6, 1, "", "AzureCancellation"], [59, 6, 1, "", "AzureNoMatch"]], "speechtotext.model.azureWrapper.AzureAPIVersion": [[56, 2, 1, "", "AZURE_DEFAULT"]], "speechtotext.model.azureWrapper.AzureAPIWrapper": [[57, 2, 1, "", "LANGUAGE_CODE"], [57, 2, 1, "", "PATH_OF_TEMP_CONVERTED_AUDIO_FILE"], [57, 3, 1, "", "_append_error"], [57, 3, 1, "", "_benchmark_sample_with_time"], [57, 3, 1, "", "benchmark_n_samples"], [57, 3, 1, "", "benchmark_sample"], [57, 3, 1, "", "benchmark_samples"], [57, 3, 1, "", "convert_sample"], [57, 3, 1, "", "get_model"]], "speechtotext.model.deepgramWrapper": [[61, 1, 1, "", "DeepgramAPIVersion"], [62, 1, 1, "", "DeepgramAPIWrapper"]], "speechtotext.model.deepgramWrapper.DeepgramAPIVersion": [[61, 2, 1, "", "DEEPGRAM_DEFAULT"], [61, 2, 1, "", "DEEPGRAM_ENHANCED"]], "speechtotext.model.deepgramWrapper.DeepgramAPIWrapper": [[62, 2, 1, "", "LANGUAGE_CODE"], [62, 2, 1, "", "PATH_OF_TEMP_CONVERTED_AUDIO_FILE"], [62, 3, 1, "", "_append_error"], [62, 3, 1, "", "_benchmark_sample_with_time"], [62, 3, 1, "", "benchmark_n_samples"], [62, 3, 1, "", "benchmark_sample"], [62, 3, 1, "", "benchmark_samples"], [62, 3, 1, "", "convert_sample"], [62, 3, 1, "", "get_model"]], "speechtotext.model.googleWrapper": [[64, 1, 1, "", "GoogleAPIVersion"], [65, 1, 1, "", "GoogleAPIWrapper"]], "speechtotext.model.googleWrapper.GoogleAPIVersion": [[64, 2, 1, "", "GOOGLE_DEFAULT"]], "speechtotext.model.googleWrapper.GoogleAPIWrapper": [[65, 2, 1, "", "LANGUAGE_CODE"], [65, 2, 1, "", "PATH_OF_TEMP_CONVERTED_AUDIO_FILE"], [65, 3, 1, "", "_append_error"], [65, 3, 1, "", "_benchmark_sample_with_time"], [65, 3, 1, "", "benchmark_n_samples"], [65, 3, 1, "", "benchmark_sample"], [65, 3, 1, "", "benchmark_samples"], [65, 3, 1, "", "convert_sample"], [65, 3, 1, "", "get_model"]], "speechtotext.model.modelWrapper": [[67, 1, 1, "", "MetaModelWrapper"], [68, 1, 1, "", "ModelVersion"], [69, 1, 1, "", "ModelWrapper"]], "speechtotext.model.modelWrapper.MetaModelWrapper": [[67, 3, 1, "", "__call__"], [67, 3, 1, "", "__new__"], [67, 3, 1, "", "mro"], [67, 3, 1, "", "wrap"]], "speechtotext.model.modelWrapper.ModelWrapper": [[69, 2, 1, "", "PATH_OF_TEMP_CONVERTED_AUDIO_FILE"], [69, 3, 1, "", "_append_error"], [69, 3, 1, "", "_benchmark_sample_with_time"], [69, 3, 1, "", "benchmark_n_samples"], [69, 3, 1, "", "benchmark_sample"], [69, 3, 1, "", "benchmark_samples"], [69, 3, 1, "", "convert_sample"], [69, 3, 1, "", "get_model"]], "speechtotext.model.speechmaticsWrapper": [[71, 1, 1, "", "SpeechmaticsAPIVersion"], [72, 1, 1, "", "SpeechmaticsAPIWrapper"]], "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIVersion": [[71, 2, 1, "", "SPEECHMATICS_DEFAULT"]], "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper": [[72, 2, 1, "", "CONNECTION_URL"], [72, 2, 1, "", "LANGUAGE_CODE"], [72, 2, 1, "", "PATH_OF_TEMP_CONVERTED_AUDIO_FILE"], [72, 3, 1, "", "_append_error"], [72, 3, 1, "", "_benchmark_sample_with_time"], [72, 3, 1, "", "benchmark_n_samples"], [72, 3, 1, "", "benchmark_sample"], [72, 3, 1, "", "benchmark_samples"], [72, 3, 1, "", "convert_sample"], [72, 3, 1, "", "get_model"]], "speechtotext.model.whisperWrapper": [[74, 1, 1, "", "WhisperAPIVersion"], [75, 1, 1, "", "WhisperAPIWrapper"], [76, 1, 1, "", "WhisperVersion"], [77, 1, 1, "", "WhisperWrapper"]], "speechtotext.model.whisperWrapper.WhisperAPIVersion": [[74, 2, 1, "", "WHISPER_1"]], "speechtotext.model.whisperWrapper.WhisperAPIWrapper": [[75, 2, 1, "", "PATH_OF_TEMP_CONVERTED_AUDIO_FILE"], [75, 3, 1, "", "_append_error"], [75, 3, 1, "", "_benchmark_sample_with_time"], [75, 3, 1, "", "benchmark_n_samples"], [75, 3, 1, "", "benchmark_sample"], [75, 3, 1, "", "benchmark_samples"], [75, 3, 1, "", "convert_sample"], [75, 3, 1, "", "get_model"]], "speechtotext.model.whisperWrapper.WhisperVersion": [[76, 2, 1, "", "BASE"], [76, 2, 1, "", "LARGE"], [76, 2, 1, "", "MEDIUM"], [76, 2, 1, "", "SMALL"], [76, 2, 1, "", "TINY"]], "speechtotext.model.whisperWrapper.WhisperWrapper": [[77, 2, 1, "", "PATH_OF_TEMP_CONVERTED_AUDIO_FILE"], [77, 3, 1, "", "_append_error"], [77, 3, 1, "", "_benchmark_sample_with_time"], [77, 3, 1, "", "benchmark_n_samples"], [77, 3, 1, "", "benchmark_sample"], [77, 3, 1, "", "benchmark_samples"], [77, 3, 1, "", "convert_sample"], [77, 3, 1, "", "get_model"]], "speechtotext.plot": [[79, 0, 0, "-", "customErrorPlots"], [83, 0, 0, "-", "customPlots"], [87, 0, 0, "-", "plotting"]], "speechtotext.plot.customErrorPlots": [[80, 1, 1, "", "ErrorCountByModel"], [81, 1, 1, "", "ErrorCountByModelByDataset"], [82, 1, 1, "", "ErrorCountHeatmap"]], "speechtotext.plot.customErrorPlots.ErrorCountByModel": [[80, 3, 1, "", "create_plot"], [80, 3, 1, "", "save"]], "speechtotext.plot.customErrorPlots.ErrorCountByModelByDataset": [[81, 3, 1, "", "create_plot"], [81, 3, 1, "", "save"]], "speechtotext.plot.customErrorPlots.ErrorCountHeatmap": [[82, 3, 1, "", "create_plot"], [82, 3, 1, "", "save"]], "speechtotext.plot.customPlots": [[84, 1, 1, "", "DynamicallyByModelNameByDataset"], [85, 1, 1, "", "DynamicallyByModelNameForEachDataset"], [86, 1, 1, "", "MetricHeatMap"]], "speechtotext.plot.customPlots.DynamicallyByModelNameByDataset": [[84, 3, 1, "", "create_plot_classes"], [84, 3, 1, "", "save"]], "speechtotext.plot.customPlots.DynamicallyByModelNameForEachDataset": [[85, 3, 1, "", "create_plot"], [85, 3, 1, "", "create_plot_classes"], [85, 3, 1, "", "save"]], "speechtotext.plot.customPlots.MetricHeatMap": [[86, 3, 1, "", "create_plot"], [86, 3, 1, "", "save"]], "speechtotext.plot.plotting": [[88, 1, 1, "", "BaseMatPlotLib"], [89, 1, 1, "", "BasePlotly"], [90, 1, 1, "", "DynamicPlotClassesByMetricByDataset"], [91, 1, 1, "", "DynamicPlotClassesByMetricForEachDataset"], [92, 1, 1, "", "Plotting"]], "speechtotext.plot.plotting.BaseMatPlotLib": [[88, 3, 1, "", "create_plot"], [88, 3, 1, "", "save"]], "speechtotext.plot.plotting.BasePlotly": [[89, 3, 1, "", "create_plot"], [89, 3, 1, "", "save"]], "speechtotext.plot.plotting.DynamicPlotClassesByMetricByDataset": [[90, 3, 1, "", "create_plot_classes"], [90, 3, 1, "", "save"]], "speechtotext.plot.plotting.DynamicPlotClassesByMetricForEachDataset": [[91, 3, 1, "", "create_plot"], [91, 3, 1, "", "create_plot_classes"], [91, 3, 1, "", "save"]], "speechtotext.plot.plotting.Plotting": [[92, 2, 1, "", "CUSTOM_ERRORS"], [92, 2, 1, "", "CUSTOM_ERROR_PLOTS"], [92, 2, 1, "", "CUSTOM_PLOTS"], [92, 2, 1, "", "CUSTOM_RESULTS"], [92, 2, 1, "", "DATASET_NAMES"], [92, 3, 1, "", "launch_dtale"], [92, 3, 1, "", "save_all"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:attribute", "3": "py:method", "4": "py:function", "5": "py:data", "6": "py:exception"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "attribute", "Python attribute"], "3": ["py", "method", "Python method"], "4": ["py", "function", "Python function"], "5": ["py", "data", "Python data"], "6": ["py", "exception", "Python exception"]}, "titleterms": {"speechtotext": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97], "benchmark": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 94], "run_benchmark": 4, "custombenchmark": [5, 6, 7, 8, 9, 10, 11, 12, 13], "amazonapibenchmark": 6, "assemblyaiapibenchmark": 7, "azureapibenchmark": 8, "deepgramapibenchmark": 9, "googleapibenchmark": 10, "speechmaticsapibenchmark": 11, "whisperapibenchmark": 12, "whisperbenchmark": 13, "dataset": [14, 15, 16, 17], "datasetbar": 16, "sampledataset": 17, "function": [18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38], "baseresult": 19, "default_csv_nam": 20, "default_datetime_format": 21, "default_reports_fold": 22, "notranscriptreturn": 23, "regex_string_pars": 24, "requiredenvvariablesmiss": 25, "benchmark_results_to_csv": 26, "force_cudnn_initi": 27, "get_extention_of_file_nam": 28, "get_file_name_without_extent": 29, "join_benchmark_result": 30, "load_env_vari": 31, "multidispatch": 32, "save_folder_nam": 33, "save_sub_folder_nam": 34, "separate_benchmark_results_by_model": 35, "string_clean": 36, "time": 37, "uppercase_for_first_character_in_str": 38, "metric": [39, 40, 41, 42, 43, 44, 45, 46], "custommetr": [40, 41, 42, 43, 44], "basemetr": 41, "benchmarkresult": 42, "errormetr": 43, "resultmetr": 44, "model": [47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 94], "amazonwrapp": [48, 49, 50, 51], "amazonapivers": 49, "amazonapiwrapp": 50, "amazon_delete_job": 51, "assemblyaiwrapp": [52, 53, 54], "assemblyaiapivers": 53, "assemblyaiapiwrapp": 54, "azurewrapp": [55, 56, 57, 58, 59], "azureapivers": 56, "azureapiwrapp": 57, "azurecancel": 58, "azurenomatch": 59, "deepgramwrapp": [60, 61, 62], "deepgramapivers": 61, "deepgramapiwrapp": 62, "googlewrapp": [63, 64, 65], "googleapivers": 64, "googleapiwrapp": 65, "modelwrapp": [66, 67, 68, 69, 94], "metamodelwrapp": 67, "modelvers": 68, "speechmaticswrapp": [70, 71, 72], "speechmaticsapivers": 71, "speechmaticsapiwrapp": 72, "whisperwrapp": [73, 74, 75, 76, 77], "whisperapivers": 74, "whisperapiwrapp": 75, "whispervers": 76, "plot": [78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92], "customerrorplot": [79, 80, 81, 82], "errorcountbymodel": 80, "errorcountbymodelbydataset": 81, "errorcountheatmap": 82, "customplot": [83, 84, 85, 86], "dynamicallybymodelnamebydataset": 84, "dynamicallybymodelnameforeachdataset": 85, "metricheatmap": 86, "basematplotlib": 88, "baseplotli": 89, "dynamicplotclassesbymetricbydataset": 90, "dynamicplotclassesbymetricforeachdataset": 91, "code": 94, "exampl": 94, "full": 94, "usag": 94, "add": 94, "new": 94, "wrapper": 94, "creat": 94, "us": 94, "custom": 94, "welcom": 95, "": 95, "document": 95, "get": 95, "start": 95, "packag": 95, "content": [95, 97], "indic": 95, "tabl": 95, "instal": 96, "conda": 96, "pip": 96, "requir": 97, "overview": 97, "env": 97, "whisper": 97, "api": 97, "amazon": 97, "transcrib": 97, "googl": 97, "deepgram": 97, "assemblyai": 97, "azur": 97, "speechmat": 97}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.viewcode": 1, "nbsphinx": 4, "sphinx": 57}, "alltitles": {"speechtotext": [[0, "module-speechtotext"], [93, "speechtotext"]], "speechtotext.benchmark": [[1, "module-speechtotext.benchmark"]], "speechtotext.benchmark.benchmarks": [[2, "module-speechtotext.benchmark.benchmarks"]], "speechtotext.benchmark.benchmarks.Benchmark": [[3, "speechtotext-benchmark-benchmarks-benchmark"]], "speechtotext.benchmark.benchmarks.run_benchmarks": [[4, "speechtotext-benchmark-benchmarks-run-benchmarks"]], "speechtotext.benchmark.customBenchmarks": [[5, "module-speechtotext.benchmark.customBenchmarks"]], "speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark": [[6, "speechtotext-benchmark-custombenchmarks-amazonapibenchmark"]], "speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark": [[7, "speechtotext-benchmark-custombenchmarks-assemblyaiapibenchmark"]], "speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark": [[8, "speechtotext-benchmark-custombenchmarks-azureapibenchmark"]], "speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark": [[9, "speechtotext-benchmark-custombenchmarks-deepgramapibenchmark"]], "speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark": [[10, "speechtotext-benchmark-custombenchmarks-googleapibenchmark"]], "speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark": [[11, "speechtotext-benchmark-custombenchmarks-speechmaticsapibenchmark"]], "speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark": [[12, "speechtotext-benchmark-custombenchmarks-whisperapibenchmark"]], "speechtotext.benchmark.customBenchmarks.WhisperBenchmark": [[13, "speechtotext-benchmark-custombenchmarks-whisperbenchmark"]], "speechtotext.datasets": [[14, "module-speechtotext.datasets"]], "speechtotext.datasets.Dataset": [[15, "speechtotext-datasets-dataset"]], "speechtotext.datasets.DatasetBare": [[16, "speechtotext-datasets-datasetbare"]], "speechtotext.datasets.SampleDataset": [[17, "speechtotext-datasets-sampledataset"]], "speechtotext.functions": [[18, "module-speechtotext.functions"]], "speechtotext.functions.BaseResult": [[19, "speechtotext-functions-baseresult"]], "speechtotext.functions.DEFAULT_CSV_NAME": [[20, "speechtotext-functions-default-csv-name"]], "speechtotext.functions.DEFAULT_DATETIME_FORMAT": [[21, "speechtotext-functions-default-datetime-format"]], "speechtotext.functions.DEFAULT_REPORTS_FOLDER": [[22, "speechtotext-functions-default-reports-folder"]], "speechtotext.functions.NoTranscriptReturned": [[23, "speechtotext-functions-notranscriptreturned"]], "speechtotext.functions.REGEX_STRING_PARSE": [[24, "speechtotext-functions-regex-string-parse"]], "speechtotext.functions.RequiredEnvVariablesMissing": [[25, "speechtotext-functions-requiredenvvariablesmissing"]], "speechtotext.functions.benchmark_results_to_csv": [[26, "speechtotext-functions-benchmark-results-to-csv"]], "speechtotext.functions.force_cudnn_initialization": [[27, "speechtotext-functions-force-cudnn-initialization"]], "speechtotext.functions.get_extention_of_file_name": [[28, "speechtotext-functions-get-extention-of-file-name"]], "speechtotext.functions.get_file_name_without_extention": [[29, "speechtotext-functions-get-file-name-without-extention"]], "speechtotext.functions.join_benchmark_results": [[30, "speechtotext-functions-join-benchmark-results"]], "speechtotext.functions.load_env_variable": [[31, "speechtotext-functions-load-env-variable"]], "speechtotext.functions.multidispatch": [[32, "speechtotext-functions-multidispatch"]], "speechtotext.functions.save_folder_name": [[33, "speechtotext-functions-save-folder-name"]], "speechtotext.functions.save_sub_folder_name": [[34, "speechtotext-functions-save-sub-folder-name"]], "speechtotext.functions.separate_benchmark_results_by_model": [[35, "speechtotext-functions-separate-benchmark-results-by-model"]], "speechtotext.functions.string_cleaning": [[36, "speechtotext-functions-string-cleaning"]], "speechtotext.functions.timing": [[37, "speechtotext-functions-timing"]], "speechtotext.functions.uppercase_for_first_character_in_string": [[38, "speechtotext-functions-uppercase-for-first-character-in-string"]], "speechtotext.metric": [[39, "module-speechtotext.metric"]], "speechtotext.metric.customMetrics": [[40, "module-speechtotext.metric.customMetrics"]], "speechtotext.metric.customMetrics.BaseMetrics": [[41, "speechtotext-metric-custommetrics-basemetrics"]], "speechtotext.metric.customMetrics.BenchmarkResults": [[42, "speechtotext-metric-custommetrics-benchmarkresults"]], "speechtotext.metric.customMetrics.ErrorMetrics": [[43, "speechtotext-metric-custommetrics-errormetrics"]], "speechtotext.metric.customMetrics.ResultMetrics": [[44, "speechtotext-metric-custommetrics-resultmetrics"]], "speechtotext.metric.metrics": [[45, "module-speechtotext.metric.metrics"]], "speechtotext.metric.metrics.Metrics": [[46, "speechtotext-metric-metrics-metrics"]], "speechtotext.model": [[47, "module-speechtotext.model"]], "speechtotext.model.amazonWrapper": [[48, "module-speechtotext.model.amazonWrapper"]], "speechtotext.model.amazonWrapper.AmazonAPIVersion": [[49, "speechtotext-model-amazonwrapper-amazonapiversion"]], "speechtotext.model.amazonWrapper.AmazonAPIWrapper": [[50, "speechtotext-model-amazonwrapper-amazonapiwrapper"]], "speechtotext.model.amazonWrapper.amazon_delete_job": [[51, "speechtotext-model-amazonwrapper-amazon-delete-job"]], "speechtotext.model.assemblyAIWrapper": [[52, "module-speechtotext.model.assemblyAIWrapper"]], "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIVersion": [[53, "speechtotext-model-assemblyaiwrapper-assemblyaiapiversion"]], "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper": [[54, "speechtotext-model-assemblyaiwrapper-assemblyaiapiwrapper"]], "speechtotext.model.azureWrapper": [[55, "module-speechtotext.model.azureWrapper"]], "speechtotext.model.azureWrapper.AzureAPIVersion": [[56, "speechtotext-model-azurewrapper-azureapiversion"]], "speechtotext.model.azureWrapper.AzureAPIWrapper": [[57, "speechtotext-model-azurewrapper-azureapiwrapper"]], "speechtotext.model.azureWrapper.AzureCancellation": [[58, "speechtotext-model-azurewrapper-azurecancellation"]], "speechtotext.model.azureWrapper.AzureNoMatch": [[59, "speechtotext-model-azurewrapper-azurenomatch"]], "speechtotext.model.deepgramWrapper": [[60, "module-speechtotext.model.deepgramWrapper"]], "speechtotext.model.deepgramWrapper.DeepgramAPIVersion": [[61, "speechtotext-model-deepgramwrapper-deepgramapiversion"]], "speechtotext.model.deepgramWrapper.DeepgramAPIWrapper": [[62, "speechtotext-model-deepgramwrapper-deepgramapiwrapper"]], "speechtotext.model.googleWrapper": [[63, "module-speechtotext.model.googleWrapper"]], "speechtotext.model.googleWrapper.GoogleAPIVersion": [[64, "speechtotext-model-googlewrapper-googleapiversion"]], "speechtotext.model.googleWrapper.GoogleAPIWrapper": [[65, "speechtotext-model-googlewrapper-googleapiwrapper"]], "speechtotext.model.modelWrapper": [[66, "module-speechtotext.model.modelWrapper"]], "speechtotext.model.modelWrapper.MetaModelWrapper": [[67, "speechtotext-model-modelwrapper-metamodelwrapper"]], "speechtotext.model.modelWrapper.ModelVersion": [[68, "speechtotext-model-modelwrapper-modelversion"]], "speechtotext.model.modelWrapper.ModelWrapper": [[69, "speechtotext-model-modelwrapper-modelwrapper"]], "speechtotext.model.speechmaticsWrapper": [[70, "module-speechtotext.model.speechmaticsWrapper"]], "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIVersion": [[71, "speechtotext-model-speechmaticswrapper-speechmaticsapiversion"]], "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper": [[72, "speechtotext-model-speechmaticswrapper-speechmaticsapiwrapper"]], "speechtotext.model.whisperWrapper": [[73, "module-speechtotext.model.whisperWrapper"]], "speechtotext.model.whisperWrapper.WhisperAPIVersion": [[74, "speechtotext-model-whisperwrapper-whisperapiversion"]], "speechtotext.model.whisperWrapper.WhisperAPIWrapper": [[75, "speechtotext-model-whisperwrapper-whisperapiwrapper"]], "speechtotext.model.whisperWrapper.WhisperVersion": [[76, "speechtotext-model-whisperwrapper-whisperversion"]], "speechtotext.model.whisperWrapper.WhisperWrapper": [[77, "speechtotext-model-whisperwrapper-whisperwrapper"]], "speechtotext.plot": [[78, "module-speechtotext.plot"]], "speechtotext.plot.customErrorPlots": [[79, "module-speechtotext.plot.customErrorPlots"]], "speechtotext.plot.customErrorPlots.ErrorCountByModel": [[80, "speechtotext-plot-customerrorplots-errorcountbymodel"]], "speechtotext.plot.customErrorPlots.ErrorCountByModelByDataset": [[81, "speechtotext-plot-customerrorplots-errorcountbymodelbydataset"]], "speechtotext.plot.customErrorPlots.ErrorCountHeatmap": [[82, "speechtotext-plot-customerrorplots-errorcountheatmap"]], "speechtotext.plot.customPlots": [[83, "module-speechtotext.plot.customPlots"]], "speechtotext.plot.customPlots.DynamicallyByModelNameByDataset": [[84, "speechtotext-plot-customplots-dynamicallybymodelnamebydataset"]], "speechtotext.plot.customPlots.DynamicallyByModelNameForEachDataset": [[85, "speechtotext-plot-customplots-dynamicallybymodelnameforeachdataset"]], "speechtotext.plot.customPlots.MetricHeatMap": [[86, "speechtotext-plot-customplots-metricheatmap"]], "speechtotext.plot.plotting": [[87, "module-speechtotext.plot.plotting"]], "speechtotext.plot.plotting.BaseMatPlotLib": [[88, "speechtotext-plot-plotting-basematplotlib"]], "speechtotext.plot.plotting.BasePlotly": [[89, "speechtotext-plot-plotting-baseplotly"]], "speechtotext.plot.plotting.DynamicPlotClassesByMetricByDataset": [[90, "speechtotext-plot-plotting-dynamicplotclassesbymetricbydataset"]], "speechtotext.plot.plotting.DynamicPlotClassesByMetricForEachDataset": [[91, "speechtotext-plot-plotting-dynamicplotclassesbymetricforeachdataset"]], "speechtotext.plot.plotting.Plotting": [[92, "speechtotext-plot-plotting-plotting"]], "Code Examples for speechtotext": [[94, "code-examples-for-speechtotext"]], "Full usage example": [[94, "full-usage-example"]], "Add new model wrapper and benchmark": [[94, "add-new-model-wrapper-and-benchmark"]], "Create new ModelWrapper": [[94, "create-new-modelwrapper"]], "Create new Benchmark": [[94, "create-new-benchmark"]], "Use custom benchmarks": [[94, "use-custom-benchmarks"]], "Welcome to speechtotext\u2019s documentation!": [[95, "welcome-to-speechtotext-s-documentation"]], "Get started": [[95, null]], "Package Contents": [[95, null]], "Indices and tables": [[95, "indices-and-tables"]], "Installation for speechtotext": [[96, "installation-for-speechtotext"]], "conda": [[96, "conda"]], "pip": [[96, "pip"]], "Requirements for speechtotext": [[97, "requirements-for-speechtotext"]], "Overview": [[97, "overview"]], "Content of .env": [[97, "content-of-env"]], "Whisper API": [[97, "whisper-api"]], "Amazon transcribe": [[97, "amazon-transcribe"]], "Google API": [[97, "google-api"]], "Deepgram API": [[97, "deepgram-api"]], "AssemblyAI API": [[97, "assemblyai-api"]], "Azure API": [[97, "azure-api"]], "Speechmatics API": [[97, "speechmatics-api"]]}, "indexentries": {"module": [[0, "module-speechtotext"], [1, "module-speechtotext.benchmark"], [2, "module-speechtotext.benchmark.benchmarks"], [5, "module-speechtotext.benchmark.customBenchmarks"], [14, "module-speechtotext.datasets"], [18, "module-speechtotext.functions"], [39, "module-speechtotext.metric"], [40, "module-speechtotext.metric.customMetrics"], [45, "module-speechtotext.metric.metrics"], [47, "module-speechtotext.model"], [48, "module-speechtotext.model.amazonWrapper"], [52, "module-speechtotext.model.assemblyAIWrapper"], [55, "module-speechtotext.model.azureWrapper"], [60, "module-speechtotext.model.deepgramWrapper"], [63, "module-speechtotext.model.googleWrapper"], [66, "module-speechtotext.model.modelWrapper"], [70, "module-speechtotext.model.speechmaticsWrapper"], [73, "module-speechtotext.model.whisperWrapper"], [78, "module-speechtotext.plot"], [79, "module-speechtotext.plot.customErrorPlots"], [83, "module-speechtotext.plot.customPlots"], [87, "module-speechtotext.plot.plotting"]], "speechtotext": [[0, "module-speechtotext"]], "speechtotext.benchmark": [[1, "module-speechtotext.benchmark"]], "speechtotext.benchmark.benchmarks": [[2, "module-speechtotext.benchmark.benchmarks"]], "benchmark_samples (benchmark attribute)": [[3, "speechtotext.benchmark.benchmarks.Benchmark.BENCHMARK_SAMPLES"]], "benchmark (class in speechtotext.benchmark.benchmarks)": [[3, "speechtotext.benchmark.benchmarks.Benchmark"]], "dataset (benchmark attribute)": [[3, "speechtotext.benchmark.benchmarks.Benchmark.DATASET"]], "error_list (benchmark attribute)": [[3, "speechtotext.benchmark.benchmarks.Benchmark.ERROR_LIST"]], "__call__() (benchmark method)": [[3, "speechtotext.benchmark.benchmarks.Benchmark.__call__"]], "convert_to_pandas() (benchmark method)": [[3, "speechtotext.benchmark.benchmarks.Benchmark.convert_to_pandas"]], "create_models() (benchmark method)": [[3, "speechtotext.benchmark.benchmarks.Benchmark.create_models"]], "save_to_csv() (benchmark method)": [[3, "speechtotext.benchmark.benchmarks.Benchmark.save_to_csv"]], "set_dataset() (benchmark class method)": [[3, "speechtotext.benchmark.benchmarks.Benchmark.set_dataset"]], "update_samples() (benchmark class method)": [[3, "speechtotext.benchmark.benchmarks.Benchmark.update_samples"]], "run_benchmarks() (in module speechtotext.benchmark.benchmarks)": [[4, "speechtotext.benchmark.benchmarks.run_benchmarks"]], "speechtotext.benchmark.custombenchmarks": [[5, "module-speechtotext.benchmark.customBenchmarks"]], "amazonapibenchmark (class in speechtotext.benchmark.custombenchmarks)": [[6, "speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark"]], "benchmark_samples (amazonapibenchmark attribute)": [[6, "speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark.BENCHMARK_SAMPLES"]], "dataset (amazonapibenchmark attribute)": [[6, "speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark.DATASET"]], "error_list (amazonapibenchmark attribute)": [[6, "speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark.ERROR_LIST"]], "model_base (amazonapibenchmark attribute)": [[6, "speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark.MODEL_BASE"]], "__call__() (amazonapibenchmark method)": [[6, "speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark.__call__"]], "convert_to_pandas() (amazonapibenchmark method)": [[6, "speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark.convert_to_pandas"]], "create_models() (amazonapibenchmark method)": [[6, "speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark.create_models"]], "save_to_csv() (amazonapibenchmark method)": [[6, "speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark.save_to_csv"]], "set_dataset() (amazonapibenchmark class method)": [[6, "speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark.set_dataset"]], "update_samples() (amazonapibenchmark class method)": [[6, "speechtotext.benchmark.customBenchmarks.AmazonAPIBenchmark.update_samples"]], "assemblyaiapibenchmark (class in speechtotext.benchmark.custombenchmarks)": [[7, "speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark"]], "benchmark_samples (assemblyaiapibenchmark attribute)": [[7, "speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark.BENCHMARK_SAMPLES"]], "dataset (assemblyaiapibenchmark attribute)": [[7, "speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark.DATASET"]], "error_list (assemblyaiapibenchmark attribute)": [[7, "speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark.ERROR_LIST"]], "model_base (assemblyaiapibenchmark attribute)": [[7, "speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark.MODEL_BASE"]], "__call__() (assemblyaiapibenchmark method)": [[7, "speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark.__call__"]], "convert_to_pandas() (assemblyaiapibenchmark method)": [[7, "speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark.convert_to_pandas"]], "create_models() (assemblyaiapibenchmark method)": [[7, "speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark.create_models"]], "save_to_csv() (assemblyaiapibenchmark method)": [[7, "speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark.save_to_csv"]], "set_dataset() (assemblyaiapibenchmark class method)": [[7, "speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark.set_dataset"]], "update_samples() (assemblyaiapibenchmark class method)": [[7, "speechtotext.benchmark.customBenchmarks.AssemblyAIAPIBenchmark.update_samples"]], "azureapibenchmark (class in speechtotext.benchmark.custombenchmarks)": [[8, "speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark"]], "benchmark_samples (azureapibenchmark attribute)": [[8, "speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark.BENCHMARK_SAMPLES"]], "dataset (azureapibenchmark attribute)": [[8, "speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark.DATASET"]], "error_list (azureapibenchmark attribute)": [[8, "speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark.ERROR_LIST"]], "model_base (azureapibenchmark attribute)": [[8, "speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark.MODEL_BASE"]], "__call__() (azureapibenchmark method)": [[8, "speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark.__call__"]], "convert_to_pandas() (azureapibenchmark method)": [[8, "speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark.convert_to_pandas"]], "create_models() (azureapibenchmark method)": [[8, "speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark.create_models"]], "save_to_csv() (azureapibenchmark method)": [[8, "speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark.save_to_csv"]], "set_dataset() (azureapibenchmark class method)": [[8, "speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark.set_dataset"]], "update_samples() (azureapibenchmark class method)": [[8, "speechtotext.benchmark.customBenchmarks.AzureAPIBenchmark.update_samples"]], "benchmark_samples (deepgramapibenchmark attribute)": [[9, "speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark.BENCHMARK_SAMPLES"]], "dataset (deepgramapibenchmark attribute)": [[9, "speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark.DATASET"]], "deepgramapibenchmark (class in speechtotext.benchmark.custombenchmarks)": [[9, "speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark"]], "error_list (deepgramapibenchmark attribute)": [[9, "speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark.ERROR_LIST"]], "model_base (deepgramapibenchmark attribute)": [[9, "speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark.MODEL_BASE"]], "__call__() (deepgramapibenchmark method)": [[9, "speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark.__call__"]], "convert_to_pandas() (deepgramapibenchmark method)": [[9, "speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark.convert_to_pandas"]], "create_models() (deepgramapibenchmark method)": [[9, "speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark.create_models"]], "save_to_csv() (deepgramapibenchmark method)": [[9, "speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark.save_to_csv"]], "set_dataset() (deepgramapibenchmark class method)": [[9, "speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark.set_dataset"]], "update_samples() (deepgramapibenchmark class method)": [[9, "speechtotext.benchmark.customBenchmarks.DeepgramAPIBenchmark.update_samples"]], "benchmark_samples (googleapibenchmark attribute)": [[10, "speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark.BENCHMARK_SAMPLES"]], "dataset (googleapibenchmark attribute)": [[10, "speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark.DATASET"]], "error_list (googleapibenchmark attribute)": [[10, "speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark.ERROR_LIST"]], "googleapibenchmark (class in speechtotext.benchmark.custombenchmarks)": [[10, "speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark"]], "model_base (googleapibenchmark attribute)": [[10, "speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark.MODEL_BASE"]], "__call__() (googleapibenchmark method)": [[10, "speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark.__call__"]], "convert_to_pandas() (googleapibenchmark method)": [[10, "speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark.convert_to_pandas"]], "create_models() (googleapibenchmark method)": [[10, "speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark.create_models"]], "save_to_csv() (googleapibenchmark method)": [[10, "speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark.save_to_csv"]], "set_dataset() (googleapibenchmark class method)": [[10, "speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark.set_dataset"]], "update_samples() (googleapibenchmark class method)": [[10, "speechtotext.benchmark.customBenchmarks.GoogleAPIBenchmark.update_samples"]], "benchmark_samples (speechmaticsapibenchmark attribute)": [[11, "speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark.BENCHMARK_SAMPLES"]], "dataset (speechmaticsapibenchmark attribute)": [[11, "speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark.DATASET"]], "error_list (speechmaticsapibenchmark attribute)": [[11, "speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark.ERROR_LIST"]], "model_base (speechmaticsapibenchmark attribute)": [[11, "speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark.MODEL_BASE"]], "speechmaticsapibenchmark (class in speechtotext.benchmark.custombenchmarks)": [[11, "speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark"]], "__call__() (speechmaticsapibenchmark method)": [[11, "speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark.__call__"]], "convert_to_pandas() (speechmaticsapibenchmark method)": [[11, "speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark.convert_to_pandas"]], "create_models() (speechmaticsapibenchmark method)": [[11, "speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark.create_models"]], "save_to_csv() (speechmaticsapibenchmark method)": [[11, "speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark.save_to_csv"]], "set_dataset() (speechmaticsapibenchmark class method)": [[11, "speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark.set_dataset"]], "update_samples() (speechmaticsapibenchmark class method)": [[11, "speechtotext.benchmark.customBenchmarks.SpeechmaticsAPIBenchmark.update_samples"]], "benchmark_samples (whisperapibenchmark attribute)": [[12, "speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark.BENCHMARK_SAMPLES"]], "dataset (whisperapibenchmark attribute)": [[12, "speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark.DATASET"]], "error_list (whisperapibenchmark attribute)": [[12, "speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark.ERROR_LIST"]], "model_base (whisperapibenchmark attribute)": [[12, "speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark.MODEL_BASE"]], "whisperapibenchmark (class in speechtotext.benchmark.custombenchmarks)": [[12, "speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark"]], "__call__() (whisperapibenchmark method)": [[12, "speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark.__call__"]], "convert_to_pandas() (whisperapibenchmark method)": [[12, "speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark.convert_to_pandas"]], "create_models() (whisperapibenchmark method)": [[12, "speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark.create_models"]], "save_to_csv() (whisperapibenchmark method)": [[12, "speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark.save_to_csv"]], "set_dataset() (whisperapibenchmark class method)": [[12, "speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark.set_dataset"]], "update_samples() (whisperapibenchmark class method)": [[12, "speechtotext.benchmark.customBenchmarks.WhisperAPIBenchmark.update_samples"]], "benchmark_samples (whisperbenchmark attribute)": [[13, "speechtotext.benchmark.customBenchmarks.WhisperBenchmark.BENCHMARK_SAMPLES"]], "dataset (whisperbenchmark attribute)": [[13, "speechtotext.benchmark.customBenchmarks.WhisperBenchmark.DATASET"]], "error_list (whisperbenchmark attribute)": [[13, "speechtotext.benchmark.customBenchmarks.WhisperBenchmark.ERROR_LIST"]], "model_base (whisperbenchmark attribute)": [[13, "speechtotext.benchmark.customBenchmarks.WhisperBenchmark.MODEL_BASE"]], "whisperbenchmark (class in speechtotext.benchmark.custombenchmarks)": [[13, "speechtotext.benchmark.customBenchmarks.WhisperBenchmark"]], "__call__() (whisperbenchmark method)": [[13, "speechtotext.benchmark.customBenchmarks.WhisperBenchmark.__call__"]], "convert_to_pandas() (whisperbenchmark method)": [[13, "speechtotext.benchmark.customBenchmarks.WhisperBenchmark.convert_to_pandas"]], "create_models() (whisperbenchmark method)": [[13, "speechtotext.benchmark.customBenchmarks.WhisperBenchmark.create_models"]], "save_to_csv() (whisperbenchmark method)": [[13, "speechtotext.benchmark.customBenchmarks.WhisperBenchmark.save_to_csv"]], "set_dataset() (whisperbenchmark class method)": [[13, "speechtotext.benchmark.customBenchmarks.WhisperBenchmark.set_dataset"]], "update_samples() (whisperbenchmark class method)": [[13, "speechtotext.benchmark.customBenchmarks.WhisperBenchmark.update_samples"]], "speechtotext.datasets": [[14, "module-speechtotext.datasets"]], "dataset (class in speechtotext.datasets)": [[15, "speechtotext.datasets.Dataset"]], "get_n_samples() (dataset method)": [[15, "speechtotext.datasets.Dataset.get_n_samples"]], "get_path_of_fragment() (dataset method)": [[15, "speechtotext.datasets.Dataset.get_path_of_fragment"]], "get_text_of_id() (dataset method)": [[15, "speechtotext.datasets.Dataset.get_text_of_id"]], "load_transcript() (dataset method)": [[15, "speechtotext.datasets.Dataset.load_transcript"]], "number_of_samples() (dataset method)": [[15, "speechtotext.datasets.Dataset.number_of_samples"]], "validate_samples() (dataset method)": [[15, "speechtotext.datasets.Dataset.validate_samples"]], "datasetbare (class in speechtotext.datasets)": [[16, "speechtotext.datasets.DatasetBare"]], "get_path_of_fragment() (datasetbare method)": [[16, "speechtotext.datasets.DatasetBare.get_path_of_fragment"]], "get_text_of_id() (datasetbare method)": [[16, "speechtotext.datasets.DatasetBare.get_text_of_id"]], "number_of_samples() (datasetbare method)": [[16, "speechtotext.datasets.DatasetBare.number_of_samples"]], "validate_samples() (datasetbare method)": [[16, "speechtotext.datasets.DatasetBare.validate_samples"]], "sampledataset (class in speechtotext.datasets)": [[17, "speechtotext.datasets.SampleDataset"]], "get_path_of_fragment() (sampledataset method)": [[17, "speechtotext.datasets.SampleDataset.get_path_of_fragment"]], "get_text_of_id() (sampledataset method)": [[17, "speechtotext.datasets.SampleDataset.get_text_of_id"]], "number_of_samples() (sampledataset method)": [[17, "speechtotext.datasets.SampleDataset.number_of_samples"]], "validate_samples() (sampledataset method)": [[17, "speechtotext.datasets.SampleDataset.validate_samples"]], "speechtotext.functions": [[18, "module-speechtotext.functions"]], "baseresult (class in speechtotext.functions)": [[19, "speechtotext.functions.BaseResult"]], "save() (baseresult method)": [[19, "speechtotext.functions.BaseResult.save"]], "default_csv_name (in module speechtotext.functions)": [[20, "speechtotext.functions.DEFAULT_CSV_NAME"]], "default_datetime_format (in module speechtotext.functions)": [[21, "speechtotext.functions.DEFAULT_DATETIME_FORMAT"]], "default_reports_folder (in module speechtotext.functions)": [[22, "speechtotext.functions.DEFAULT_REPORTS_FOLDER"]], "notranscriptreturned": [[23, "speechtotext.functions.NoTranscriptReturned"]], "regex_string_parse (in module speechtotext.functions)": [[24, "speechtotext.functions.REGEX_STRING_PARSE"]], "requiredenvvariablesmissing": [[25, "speechtotext.functions.RequiredEnvVariablesMissing"]], "benchmark_results_to_csv() (in module speechtotext.functions)": [[26, "speechtotext.functions.benchmark_results_to_csv"]], "force_cudnn_initialization() (in module speechtotext.functions)": [[27, "speechtotext.functions.force_cudnn_initialization"]], "get_extention_of_file_name() (in module speechtotext.functions)": [[28, "speechtotext.functions.get_extention_of_file_name"]], "get_file_name_without_extention() (in module speechtotext.functions)": [[29, "speechtotext.functions.get_file_name_without_extention"]], "join_benchmark_results() (in module speechtotext.functions)": [[30, "speechtotext.functions.join_benchmark_results"]], "load_env_variable() (in module speechtotext.functions)": [[31, "speechtotext.functions.load_env_variable"]], "multidispatch() (in module speechtotext.functions)": [[32, "speechtotext.functions.multidispatch"]], "save_folder_name() (in module speechtotext.functions)": [[33, "speechtotext.functions.save_folder_name"]], "save_sub_folder_name() (in module speechtotext.functions)": [[34, "speechtotext.functions.save_sub_folder_name"]], "separate_benchmark_results_by_model() (in module speechtotext.functions)": [[35, "speechtotext.functions.separate_benchmark_results_by_model"]], "string_cleaning() (in module speechtotext.functions)": [[36, "speechtotext.functions.string_cleaning"]], "timing() (in module speechtotext.functions)": [[37, "speechtotext.functions.timing"]], "uppercase_for_first_character_in_string() (in module speechtotext.functions)": [[38, "speechtotext.functions.uppercase_for_first_character_in_string"]], "speechtotext.metric": [[39, "module-speechtotext.metric"]], "speechtotext.metric.custommetrics": [[40, "module-speechtotext.metric.customMetrics"]], "basemetrics (class in speechtotext.metric.custommetrics)": [[41, "speechtotext.metric.customMetrics.BaseMetrics"]], "create_df() (basemetrics method)": [[41, "speechtotext.metric.customMetrics.BaseMetrics.create_df"]], "save() (basemetrics method)": [[41, "speechtotext.metric.customMetrics.BaseMetrics.save"]], "benchmarkresults (class in speechtotext.metric.custommetrics)": [[42, "speechtotext.metric.customMetrics.BenchmarkResults"]], "create_df() (benchmarkresults method)": [[42, "speechtotext.metric.customMetrics.BenchmarkResults.create_df"]], "save() (benchmarkresults method)": [[42, "speechtotext.metric.customMetrics.BenchmarkResults.save"]], "errormetrics (class in speechtotext.metric.custommetrics)": [[43, "speechtotext.metric.customMetrics.ErrorMetrics"]], "create_df() (errormetrics method)": [[43, "speechtotext.metric.customMetrics.ErrorMetrics.create_df"]], "save() (errormetrics method)": [[43, "speechtotext.metric.customMetrics.ErrorMetrics.save"]], "resultmetrics (class in speechtotext.metric.custommetrics)": [[44, "speechtotext.metric.customMetrics.ResultMetrics"]], "create_df() (resultmetrics method)": [[44, "speechtotext.metric.customMetrics.ResultMetrics.create_df"]], "save() (resultmetrics method)": [[44, "speechtotext.metric.customMetrics.ResultMetrics.save"]], "speechtotext.metric.metrics": [[45, "module-speechtotext.metric.metrics"]], "metrics (class in speechtotext.metric.metrics)": [[46, "speechtotext.metric.metrics.Metrics"]], "__call__() (metrics method)": [[46, "speechtotext.metric.metrics.Metrics.__call__"]], "bleu (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.bleu"]], "cer (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.cer"]], "deletions (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.deletions"]], "duration (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.duration"]], "get_all_metric_docs() (metrics method)": [[46, "speechtotext.metric.metrics.Metrics.get_all_metric_docs"]], "get_all_metric_names() (metrics method)": [[46, "speechtotext.metric.metrics.Metrics.get_all_metric_names"]], "hits (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.hits"]], "insertions (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.insertions"]], "mer (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.mer"]], "meteor (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.meteor"]], "rouge_1_f (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.rouge_1_f"]], "rouge_1_p (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.rouge_1_p"]], "rouge_1_r (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.rouge_1_r"]], "rouge_2_f (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.rouge_2_f"]], "rouge_2_p (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.rouge_2_p"]], "rouge_2_r (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.rouge_2_r"]], "rouge_l_f (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.rouge_l_f"]], "rouge_l_p (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.rouge_l_p"]], "rouge_l_r (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.rouge_l_r"]], "substitutions (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.substitutions"]], "wer (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.wer"]], "wil (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.wil"]], "wip (metrics attribute)": [[46, "speechtotext.metric.metrics.Metrics.wip"]], "speechtotext.model": [[47, "module-speechtotext.model"]], "speechtotext.model.amazonwrapper": [[48, "module-speechtotext.model.amazonWrapper"]], "amazon_default (amazonapiversion attribute)": [[49, "speechtotext.model.amazonWrapper.AmazonAPIVersion.AMAZON_DEFAULT"]], "amazonapiversion (class in speechtotext.model.amazonwrapper)": [[49, "speechtotext.model.amazonWrapper.AmazonAPIVersion"]], "amazonapiwrapper (class in speechtotext.model.amazonwrapper)": [[50, "speechtotext.model.amazonWrapper.AmazonAPIWrapper"]], "bucket_exist (amazonapiwrapper attribute)": [[50, "speechtotext.model.amazonWrapper.AmazonAPIWrapper.BUCKET_EXIST"]], "language_code (amazonapiwrapper attribute)": [[50, "speechtotext.model.amazonWrapper.AmazonAPIWrapper.LANGUAGE_CODE"]], "path_of_temp_converted_audio_file (amazonapiwrapper attribute)": [[50, "speechtotext.model.amazonWrapper.AmazonAPIWrapper.PATH_OF_TEMP_CONVERTED_AUDIO_FILE"]], "_append_error() (amazonapiwrapper method)": [[50, "speechtotext.model.amazonWrapper.AmazonAPIWrapper._append_error"]], "_benchmark_sample_with_time() (amazonapiwrapper method)": [[50, "speechtotext.model.amazonWrapper.AmazonAPIWrapper._benchmark_sample_with_time"]], "_get_transcribe_file_location() (amazonapiwrapper method)": [[50, "speechtotext.model.amazonWrapper.AmazonAPIWrapper._get_transcribe_file_location"]], "_get_transcript_from_json_uri() (amazonapiwrapper method)": [[50, "speechtotext.model.amazonWrapper.AmazonAPIWrapper._get_transcript_from_json_uri"]], "benchmark_n_samples() (amazonapiwrapper method)": [[50, "speechtotext.model.amazonWrapper.AmazonAPIWrapper.benchmark_n_samples"]], "benchmark_sample() (amazonapiwrapper method)": [[50, "speechtotext.model.amazonWrapper.AmazonAPIWrapper.benchmark_sample"]], "benchmark_samples() (amazonapiwrapper method)": [[50, "speechtotext.model.amazonWrapper.AmazonAPIWrapper.benchmark_samples"]], "convert_sample() (amazonapiwrapper method)": [[50, "speechtotext.model.amazonWrapper.AmazonAPIWrapper.convert_sample"]], "get_model() (amazonapiwrapper method)": [[50, "speechtotext.model.amazonWrapper.AmazonAPIWrapper.get_model"]], "amazon_delete_job() (in module speechtotext.model.amazonwrapper)": [[51, "speechtotext.model.amazonWrapper.amazon_delete_job"]], "speechtotext.model.assemblyaiwrapper": [[52, "module-speechtotext.model.assemblyAIWrapper"]], "assemblyai_default (assemblyaiapiversion attribute)": [[53, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIVersion.ASSEMBLYAI_DEFAULT"]], "assemblyaiapiversion (class in speechtotext.model.assemblyaiwrapper)": [[53, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIVersion"]], "api_url (assemblyaiapiwrapper attribute)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper.API_URL"]], "assemblyaiapiwrapper (class in speechtotext.model.assemblyaiwrapper)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper"]], "language_code (assemblyaiapiwrapper attribute)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper.LANGUAGE_CODE"]], "path_of_temp_converted_audio_file (assemblyaiapiwrapper attribute)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper.PATH_OF_TEMP_CONVERTED_AUDIO_FILE"]], "polling_endpoint (assemblyaiapiwrapper attribute)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper.POLLING_ENDPOINT"]], "time_sleep (assemblyaiapiwrapper attribute)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper.TIME_SLEEP"]], "transcript_endpoint (assemblyaiapiwrapper attribute)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper.TRANSCRIPT_ENDPOINT"]], "upload_endpoint (assemblyaiapiwrapper attribute)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper.UPLOAD_ENDPOINT"]], "_append_error() (assemblyaiapiwrapper method)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper._append_error"]], "_benchmark_sample_with_time() (assemblyaiapiwrapper method)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper._benchmark_sample_with_time"]], "_clean_output() (assemblyaiapiwrapper method)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper._clean_output"]], "_get_paragraphs() (assemblyaiapiwrapper method)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper._get_paragraphs"]], "_make_polling_endpoint() (assemblyaiapiwrapper method)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper._make_polling_endpoint"]], "_read_file_with_chunck_size() (assemblyaiapiwrapper method)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper._read_file_with_chunck_size"]], "_request_transcript() (assemblyaiapiwrapper method)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper._request_transcript"]], "_upload_file() (assemblyaiapiwrapper method)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper._upload_file"]], "_wait_for_completion() (assemblyaiapiwrapper method)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper._wait_for_completion"]], "benchmark_n_samples() (assemblyaiapiwrapper method)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper.benchmark_n_samples"]], "benchmark_sample() (assemblyaiapiwrapper method)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper.benchmark_sample"]], "benchmark_samples() (assemblyaiapiwrapper method)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper.benchmark_samples"]], "convert_sample() (assemblyaiapiwrapper method)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper.convert_sample"]], "get_model() (assemblyaiapiwrapper method)": [[54, "speechtotext.model.assemblyAIWrapper.AssemblyAIAPIWrapper.get_model"]], "speechtotext.model.azurewrapper": [[55, "module-speechtotext.model.azureWrapper"]], "azure_default (azureapiversion attribute)": [[56, "speechtotext.model.azureWrapper.AzureAPIVersion.AZURE_DEFAULT"]], "azureapiversion (class in speechtotext.model.azurewrapper)": [[56, "speechtotext.model.azureWrapper.AzureAPIVersion"]], "azureapiwrapper (class in speechtotext.model.azurewrapper)": [[57, "speechtotext.model.azureWrapper.AzureAPIWrapper"]], "language_code (azureapiwrapper attribute)": [[57, "speechtotext.model.azureWrapper.AzureAPIWrapper.LANGUAGE_CODE"]], "path_of_temp_converted_audio_file (azureapiwrapper attribute)": [[57, "speechtotext.model.azureWrapper.AzureAPIWrapper.PATH_OF_TEMP_CONVERTED_AUDIO_FILE"]], "_append_error() (azureapiwrapper method)": [[57, "speechtotext.model.azureWrapper.AzureAPIWrapper._append_error"]], "_benchmark_sample_with_time() (azureapiwrapper method)": [[57, "speechtotext.model.azureWrapper.AzureAPIWrapper._benchmark_sample_with_time"]], "benchmark_n_samples() (azureapiwrapper method)": [[57, "speechtotext.model.azureWrapper.AzureAPIWrapper.benchmark_n_samples"]], "benchmark_sample() (azureapiwrapper method)": [[57, "speechtotext.model.azureWrapper.AzureAPIWrapper.benchmark_sample"]], "benchmark_samples() (azureapiwrapper method)": [[57, "speechtotext.model.azureWrapper.AzureAPIWrapper.benchmark_samples"]], "convert_sample() (azureapiwrapper method)": [[57, "speechtotext.model.azureWrapper.AzureAPIWrapper.convert_sample"]], "get_model() (azureapiwrapper method)": [[57, "speechtotext.model.azureWrapper.AzureAPIWrapper.get_model"]], "azurecancellation": [[58, "speechtotext.model.azureWrapper.AzureCancellation"]], "azurenomatch": [[59, "speechtotext.model.azureWrapper.AzureNoMatch"]], "speechtotext.model.deepgramwrapper": [[60, "module-speechtotext.model.deepgramWrapper"]], "deepgram_default (deepgramapiversion attribute)": [[61, "speechtotext.model.deepgramWrapper.DeepgramAPIVersion.DEEPGRAM_DEFAULT"]], "deepgram_enhanced (deepgramapiversion attribute)": [[61, "speechtotext.model.deepgramWrapper.DeepgramAPIVersion.DEEPGRAM_ENHANCED"]], "deepgramapiversion (class in speechtotext.model.deepgramwrapper)": [[61, "speechtotext.model.deepgramWrapper.DeepgramAPIVersion"]], "deepgramapiwrapper (class in speechtotext.model.deepgramwrapper)": [[62, "speechtotext.model.deepgramWrapper.DeepgramAPIWrapper"]], "language_code (deepgramapiwrapper attribute)": [[62, "speechtotext.model.deepgramWrapper.DeepgramAPIWrapper.LANGUAGE_CODE"]], "path_of_temp_converted_audio_file (deepgramapiwrapper attribute)": [[62, "speechtotext.model.deepgramWrapper.DeepgramAPIWrapper.PATH_OF_TEMP_CONVERTED_AUDIO_FILE"]], "_append_error() (deepgramapiwrapper method)": [[62, "speechtotext.model.deepgramWrapper.DeepgramAPIWrapper._append_error"]], "_benchmark_sample_with_time() (deepgramapiwrapper method)": [[62, "speechtotext.model.deepgramWrapper.DeepgramAPIWrapper._benchmark_sample_with_time"]], "benchmark_n_samples() (deepgramapiwrapper method)": [[62, "speechtotext.model.deepgramWrapper.DeepgramAPIWrapper.benchmark_n_samples"]], "benchmark_sample() (deepgramapiwrapper method)": [[62, "speechtotext.model.deepgramWrapper.DeepgramAPIWrapper.benchmark_sample"]], "benchmark_samples() (deepgramapiwrapper method)": [[62, "speechtotext.model.deepgramWrapper.DeepgramAPIWrapper.benchmark_samples"]], "convert_sample() (deepgramapiwrapper method)": [[62, "speechtotext.model.deepgramWrapper.DeepgramAPIWrapper.convert_sample"]], "get_model() (deepgramapiwrapper method)": [[62, "speechtotext.model.deepgramWrapper.DeepgramAPIWrapper.get_model"]], "speechtotext.model.googlewrapper": [[63, "module-speechtotext.model.googleWrapper"]], "google_default (googleapiversion attribute)": [[64, "speechtotext.model.googleWrapper.GoogleAPIVersion.GOOGLE_DEFAULT"]], "googleapiversion (class in speechtotext.model.googlewrapper)": [[64, "speechtotext.model.googleWrapper.GoogleAPIVersion"]], "googleapiwrapper (class in speechtotext.model.googlewrapper)": [[65, "speechtotext.model.googleWrapper.GoogleAPIWrapper"]], "language_code (googleapiwrapper attribute)": [[65, "speechtotext.model.googleWrapper.GoogleAPIWrapper.LANGUAGE_CODE"]], "path_of_temp_converted_audio_file (googleapiwrapper attribute)": [[65, "speechtotext.model.googleWrapper.GoogleAPIWrapper.PATH_OF_TEMP_CONVERTED_AUDIO_FILE"]], "_append_error() (googleapiwrapper method)": [[65, "speechtotext.model.googleWrapper.GoogleAPIWrapper._append_error"]], "_benchmark_sample_with_time() (googleapiwrapper method)": [[65, "speechtotext.model.googleWrapper.GoogleAPIWrapper._benchmark_sample_with_time"]], "benchmark_n_samples() (googleapiwrapper method)": [[65, "speechtotext.model.googleWrapper.GoogleAPIWrapper.benchmark_n_samples"]], "benchmark_sample() (googleapiwrapper method)": [[65, "speechtotext.model.googleWrapper.GoogleAPIWrapper.benchmark_sample"]], "benchmark_samples() (googleapiwrapper method)": [[65, "speechtotext.model.googleWrapper.GoogleAPIWrapper.benchmark_samples"]], "convert_sample() (googleapiwrapper method)": [[65, "speechtotext.model.googleWrapper.GoogleAPIWrapper.convert_sample"]], "get_model() (googleapiwrapper method)": [[65, "speechtotext.model.googleWrapper.GoogleAPIWrapper.get_model"]], "speechtotext.model.modelwrapper": [[66, "module-speechtotext.model.modelWrapper"]], "metamodelwrapper (class in speechtotext.model.modelwrapper)": [[67, "speechtotext.model.modelWrapper.MetaModelWrapper"]], "__call__() (metamodelwrapper method)": [[67, "speechtotext.model.modelWrapper.MetaModelWrapper.__call__"]], "__new__() (metamodelwrapper static method)": [[67, "speechtotext.model.modelWrapper.MetaModelWrapper.__new__"]], "mro() (metamodelwrapper method)": [[67, "speechtotext.model.modelWrapper.MetaModelWrapper.mro"]], "wrap() (metamodelwrapper static method)": [[67, "speechtotext.model.modelWrapper.MetaModelWrapper.wrap"]], "modelversion (class in speechtotext.model.modelwrapper)": [[68, "speechtotext.model.modelWrapper.ModelVersion"]], "modelwrapper (class in speechtotext.model.modelwrapper)": [[69, "speechtotext.model.modelWrapper.ModelWrapper"]], "path_of_temp_converted_audio_file (modelwrapper attribute)": [[69, "speechtotext.model.modelWrapper.ModelWrapper.PATH_OF_TEMP_CONVERTED_AUDIO_FILE"]], "_append_error() (modelwrapper method)": [[69, "speechtotext.model.modelWrapper.ModelWrapper._append_error"]], "_benchmark_sample_with_time() (modelwrapper method)": [[69, "speechtotext.model.modelWrapper.ModelWrapper._benchmark_sample_with_time"]], "benchmark_n_samples() (modelwrapper method)": [[69, "speechtotext.model.modelWrapper.ModelWrapper.benchmark_n_samples"]], "benchmark_sample() (modelwrapper method)": [[69, "speechtotext.model.modelWrapper.ModelWrapper.benchmark_sample"]], "benchmark_samples() (modelwrapper method)": [[69, "speechtotext.model.modelWrapper.ModelWrapper.benchmark_samples"]], "convert_sample() (modelwrapper method)": [[69, "speechtotext.model.modelWrapper.ModelWrapper.convert_sample"]], "get_model() (modelwrapper method)": [[69, "speechtotext.model.modelWrapper.ModelWrapper.get_model"]], "speechtotext.model.speechmaticswrapper": [[70, "module-speechtotext.model.speechmaticsWrapper"]], "speechmatics_default (speechmaticsapiversion attribute)": [[71, "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIVersion.SPEECHMATICS_DEFAULT"]], "speechmaticsapiversion (class in speechtotext.model.speechmaticswrapper)": [[71, "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIVersion"]], "connection_url (speechmaticsapiwrapper attribute)": [[72, "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper.CONNECTION_URL"]], "language_code (speechmaticsapiwrapper attribute)": [[72, "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper.LANGUAGE_CODE"]], "path_of_temp_converted_audio_file (speechmaticsapiwrapper attribute)": [[72, "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper.PATH_OF_TEMP_CONVERTED_AUDIO_FILE"]], "speechmaticsapiwrapper (class in speechtotext.model.speechmaticswrapper)": [[72, "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper"]], "_append_error() (speechmaticsapiwrapper method)": [[72, "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper._append_error"]], "_benchmark_sample_with_time() (speechmaticsapiwrapper method)": [[72, "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper._benchmark_sample_with_time"]], "benchmark_n_samples() (speechmaticsapiwrapper method)": [[72, "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper.benchmark_n_samples"]], "benchmark_sample() (speechmaticsapiwrapper method)": [[72, "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper.benchmark_sample"]], "benchmark_samples() (speechmaticsapiwrapper method)": [[72, "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper.benchmark_samples"]], "convert_sample() (speechmaticsapiwrapper method)": [[72, "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper.convert_sample"]], "get_model() (speechmaticsapiwrapper method)": [[72, "speechtotext.model.speechmaticsWrapper.SpeechmaticsAPIWrapper.get_model"]], "speechtotext.model.whisperwrapper": [[73, "module-speechtotext.model.whisperWrapper"]], "whisper_1 (whisperapiversion attribute)": [[74, "speechtotext.model.whisperWrapper.WhisperAPIVersion.WHISPER_1"]], "whisperapiversion (class in speechtotext.model.whisperwrapper)": [[74, "speechtotext.model.whisperWrapper.WhisperAPIVersion"]], "path_of_temp_converted_audio_file (whisperapiwrapper attribute)": [[75, "speechtotext.model.whisperWrapper.WhisperAPIWrapper.PATH_OF_TEMP_CONVERTED_AUDIO_FILE"]], "whisperapiwrapper (class in speechtotext.model.whisperwrapper)": [[75, "speechtotext.model.whisperWrapper.WhisperAPIWrapper"]], "_append_error() (whisperapiwrapper method)": [[75, "speechtotext.model.whisperWrapper.WhisperAPIWrapper._append_error"]], "_benchmark_sample_with_time() (whisperapiwrapper method)": [[75, "speechtotext.model.whisperWrapper.WhisperAPIWrapper._benchmark_sample_with_time"]], "benchmark_n_samples() (whisperapiwrapper method)": [[75, "speechtotext.model.whisperWrapper.WhisperAPIWrapper.benchmark_n_samples"]], "benchmark_sample() (whisperapiwrapper method)": [[75, "speechtotext.model.whisperWrapper.WhisperAPIWrapper.benchmark_sample"]], "benchmark_samples() (whisperapiwrapper method)": [[75, "speechtotext.model.whisperWrapper.WhisperAPIWrapper.benchmark_samples"]], "convert_sample() (whisperapiwrapper method)": [[75, "speechtotext.model.whisperWrapper.WhisperAPIWrapper.convert_sample"]], "get_model() (whisperapiwrapper method)": [[75, "speechtotext.model.whisperWrapper.WhisperAPIWrapper.get_model"]], "base (whisperversion attribute)": [[76, "speechtotext.model.whisperWrapper.WhisperVersion.BASE"]], "large (whisperversion attribute)": [[76, "speechtotext.model.whisperWrapper.WhisperVersion.LARGE"]], "medium (whisperversion attribute)": [[76, "speechtotext.model.whisperWrapper.WhisperVersion.MEDIUM"]], "small (whisperversion attribute)": [[76, "speechtotext.model.whisperWrapper.WhisperVersion.SMALL"]], "tiny (whisperversion attribute)": [[76, "speechtotext.model.whisperWrapper.WhisperVersion.TINY"]], "whisperversion (class in speechtotext.model.whisperwrapper)": [[76, "speechtotext.model.whisperWrapper.WhisperVersion"]], "path_of_temp_converted_audio_file (whisperwrapper attribute)": [[77, "speechtotext.model.whisperWrapper.WhisperWrapper.PATH_OF_TEMP_CONVERTED_AUDIO_FILE"]], "whisperwrapper (class in speechtotext.model.whisperwrapper)": [[77, "speechtotext.model.whisperWrapper.WhisperWrapper"]], "_append_error() (whisperwrapper method)": [[77, "speechtotext.model.whisperWrapper.WhisperWrapper._append_error"]], "_benchmark_sample_with_time() (whisperwrapper method)": [[77, "speechtotext.model.whisperWrapper.WhisperWrapper._benchmark_sample_with_time"]], "benchmark_n_samples() (whisperwrapper method)": [[77, "speechtotext.model.whisperWrapper.WhisperWrapper.benchmark_n_samples"]], "benchmark_sample() (whisperwrapper method)": [[77, "speechtotext.model.whisperWrapper.WhisperWrapper.benchmark_sample"]], "benchmark_samples() (whisperwrapper method)": [[77, "speechtotext.model.whisperWrapper.WhisperWrapper.benchmark_samples"]], "convert_sample() (whisperwrapper method)": [[77, "speechtotext.model.whisperWrapper.WhisperWrapper.convert_sample"]], "get_model() (whisperwrapper method)": [[77, "speechtotext.model.whisperWrapper.WhisperWrapper.get_model"]], "speechtotext.plot": [[78, "module-speechtotext.plot"]], "speechtotext.plot.customerrorplots": [[79, "module-speechtotext.plot.customErrorPlots"]], "errorcountbymodel (class in speechtotext.plot.customerrorplots)": [[80, "speechtotext.plot.customErrorPlots.ErrorCountByModel"]], "create_plot() (errorcountbymodel method)": [[80, "speechtotext.plot.customErrorPlots.ErrorCountByModel.create_plot"]], "save() (errorcountbymodel method)": [[80, "speechtotext.plot.customErrorPlots.ErrorCountByModel.save"]], "errorcountbymodelbydataset (class in speechtotext.plot.customerrorplots)": [[81, "speechtotext.plot.customErrorPlots.ErrorCountByModelByDataset"]], "create_plot() (errorcountbymodelbydataset method)": [[81, "speechtotext.plot.customErrorPlots.ErrorCountByModelByDataset.create_plot"]], "save() (errorcountbymodelbydataset method)": [[81, "speechtotext.plot.customErrorPlots.ErrorCountByModelByDataset.save"]], "errorcountheatmap (class in speechtotext.plot.customerrorplots)": [[82, "speechtotext.plot.customErrorPlots.ErrorCountHeatmap"]], "create_plot() (errorcountheatmap method)": [[82, "speechtotext.plot.customErrorPlots.ErrorCountHeatmap.create_plot"]], "save() (errorcountheatmap method)": [[82, "speechtotext.plot.customErrorPlots.ErrorCountHeatmap.save"]], "speechtotext.plot.customplots": [[83, "module-speechtotext.plot.customPlots"]], "dynamicallybymodelnamebydataset (class in speechtotext.plot.customplots)": [[84, "speechtotext.plot.customPlots.DynamicallyByModelNameByDataset"]], "create_plot_classes() (dynamicallybymodelnamebydataset method)": [[84, "speechtotext.plot.customPlots.DynamicallyByModelNameByDataset.create_plot_classes"]], "save() (dynamicallybymodelnamebydataset method)": [[84, "speechtotext.plot.customPlots.DynamicallyByModelNameByDataset.save"]], "dynamicallybymodelnameforeachdataset (class in speechtotext.plot.customplots)": [[85, "speechtotext.plot.customPlots.DynamicallyByModelNameForEachDataset"]], "create_plot() (dynamicallybymodelnameforeachdataset method)": [[85, "speechtotext.plot.customPlots.DynamicallyByModelNameForEachDataset.create_plot"]], "create_plot_classes() (dynamicallybymodelnameforeachdataset method)": [[85, "speechtotext.plot.customPlots.DynamicallyByModelNameForEachDataset.create_plot_classes"]], "save() (dynamicallybymodelnameforeachdataset method)": [[85, "speechtotext.plot.customPlots.DynamicallyByModelNameForEachDataset.save"]], "metricheatmap (class in speechtotext.plot.customplots)": [[86, "speechtotext.plot.customPlots.MetricHeatMap"]], "create_plot() (metricheatmap method)": [[86, "speechtotext.plot.customPlots.MetricHeatMap.create_plot"]], "save() (metricheatmap method)": [[86, "speechtotext.plot.customPlots.MetricHeatMap.save"]], "speechtotext.plot.plotting": [[87, "module-speechtotext.plot.plotting"]], "basematplotlib (class in speechtotext.plot.plotting)": [[88, "speechtotext.plot.plotting.BaseMatPlotLib"]], "create_plot() (basematplotlib method)": [[88, "speechtotext.plot.plotting.BaseMatPlotLib.create_plot"]], "save() (basematplotlib method)": [[88, "speechtotext.plot.plotting.BaseMatPlotLib.save"]], "baseplotly (class in speechtotext.plot.plotting)": [[89, "speechtotext.plot.plotting.BasePlotly"]], "create_plot() (baseplotly method)": [[89, "speechtotext.plot.plotting.BasePlotly.create_plot"]], "save() (baseplotly method)": [[89, "speechtotext.plot.plotting.BasePlotly.save"]], "dynamicplotclassesbymetricbydataset (class in speechtotext.plot.plotting)": [[90, "speechtotext.plot.plotting.DynamicPlotClassesByMetricByDataset"]], "create_plot_classes() (dynamicplotclassesbymetricbydataset method)": [[90, "speechtotext.plot.plotting.DynamicPlotClassesByMetricByDataset.create_plot_classes"]], "save() (dynamicplotclassesbymetricbydataset method)": [[90, "speechtotext.plot.plotting.DynamicPlotClassesByMetricByDataset.save"]], "dynamicplotclassesbymetricforeachdataset (class in speechtotext.plot.plotting)": [[91, "speechtotext.plot.plotting.DynamicPlotClassesByMetricForEachDataset"]], "create_plot() (dynamicplotclassesbymetricforeachdataset method)": [[91, "speechtotext.plot.plotting.DynamicPlotClassesByMetricForEachDataset.create_plot"]], "create_plot_classes() (dynamicplotclassesbymetricforeachdataset method)": [[91, "speechtotext.plot.plotting.DynamicPlotClassesByMetricForEachDataset.create_plot_classes"]], "save() (dynamicplotclassesbymetricforeachdataset method)": [[91, "speechtotext.plot.plotting.DynamicPlotClassesByMetricForEachDataset.save"]], "custom_errors (plotting attribute)": [[92, "speechtotext.plot.plotting.Plotting.CUSTOM_ERRORS"]], "custom_error_plots (plotting attribute)": [[92, "speechtotext.plot.plotting.Plotting.CUSTOM_ERROR_PLOTS"]], "custom_plots (plotting attribute)": [[92, "speechtotext.plot.plotting.Plotting.CUSTOM_PLOTS"]], "custom_results (plotting attribute)": [[92, "speechtotext.plot.plotting.Plotting.CUSTOM_RESULTS"]], "dataset_names (plotting attribute)": [[92, "speechtotext.plot.plotting.Plotting.DATASET_NAMES"]], "plotting (class in speechtotext.plot.plotting)": [[92, "speechtotext.plot.plotting.Plotting"]], "launch_dtale() (plotting method)": [[92, "speechtotext.plot.plotting.Plotting.launch_dtale"]], "save_all() (plotting method)": [[92, "speechtotext.plot.plotting.Plotting.save_all"]]}})