Search.setIndex({"docnames": ["index", "speechtotext/benchmarks", "speechtotext/datasets", "speechtotext/functions", "speechtotext/index", "speechtotext/metrics", "speechtotext/models/index"], "filenames": ["index.rst", "speechtotext/benchmarks.rst", "speechtotext/datasets.rst", "speechtotext/functions.rst", "speechtotext/index.rst", "speechtotext/metrics.rst", "speechtotext/models/index.rst"], "titles": ["Welcome to speechtotext\u2019s documentation!", "Benchmarks", "Datasets", "Functions", "Speechtotext package", "Metrics", "Speechtotext models package"], "terms": {"class": [1, 2, 3, 5, 6], "base": [1, 2, 5, 6], "object": [2, 5], "set": [1, 2, 3, 6], "proport": [], "integr": [], "deriv": [], "control": [], "genout": [], "error": 5, "float": 5, "calcul": 5, "paramet": [1, 2, 3, 5, 6], "valu": 6, "return": [1, 2, 3, 6], "type": [1, 2, 3, 5, 6], "initi": [], "variabl": [], "setkd": [], "invar": [], "k_": [], "d": [], "setki": [], "i": 1, "setkp": [], "p": [], "setpreverror": [], "preverror": [], "previou": [], "packag": [0, 2, 3], "submodul": 0, "info": [], "modul": [0, 4], "function": 4, "pid": [], "index": [0, 3], "search": 0, "page": 0, "threadsafesingleton": [], "creat": [1, 2, 3, 5, 6], "device_exist": [], "path": [1, 2, 6], "str": [1, 2, 3, 5, 6], "bool": [3, 6], "thi": [1, 2, 3, 5, 6], "check": [], "an": 1, "devic": [], "exist": 2, "linux": [], "dev": [], "tty": [], "exampl": [], "true": [1, 3, 5, 6], "set_max_limit": [], "int": [1, 2, 6], "max": [], "maximum": [], "limit": [], "2": [], "set_min_limit": [], "min": [], "minimum": [], "get_cpu_tempfunc": [], "cpu": [], "temperatur": [], "get_cpu_us": [], "usag": [], "us": [1, 2, 3, 5, 6], "psutil": [], "get_gpu_tempfunc": [], "gpu": [], "charact": 5, "string": [2, 3], "get_ram_info": [], "ram": [], "get_swap_info": [], "swap": [], "memori": [], "packagenam": [], "dataset": [1, 4, 5, 6], "metric": [1, 4, 6], "dir": [1, 2, 6], "file_ext": 2, "wav": 2, "get_path_of_frag": 2, "id": [2, 5, 6], "get": [2, 6], "fragment": 2, "file": [2, 5, 6], "rais": 2, "filenotfounderror": 2, "doesn": 2, "t": 2, "_description_": [], "get_text_of_id": 2, "text": [2, 3, 6], "spoken": 2, "load_transcript": 2, "load": 2, "transcript": [2, 3, 5, 6], "refer": 5, "hypothesi": 5, "with_clean": [1, 5, 6], "_summary_": [], "attribut": 5, "class_attribut": 5, "The": 5, "wer": 5, "word": 5, "rate": 5, "mer": 5, "match": 5, "wil": 5, "inform": 5, "lost": 5, "wip": 5, "preserv": 5, "cer": 5, "notebook_metrics_print": 5, "string_clean": 3, "clean": [3, 6], "stt": 3, "unclean": 3, "model": [0, 1, 3, 5], "whisperwrapp": 0, "force_cudnn_initi": 3, "forc": 3, "cuda": 3, "torch": 3, "whisper": [1, 6], "model_vers": 6, "whispermodel": [], "model_dir": [], "benchmark_sampl": [1, 6], "get_model": 6, "get_transcript_of_fil": 6, "audio_file_nam": 6, "enum": 6, "enumer": [], "larg": 6, "medium": 6, "small": 6, "tini": 6, "number_of_sampl": [1, 2, 6], "number": [1, 2, 6], "sampl": [1, 2, 6], "avail": 6, "wrapper": [1, 6], "benchmark_n_sampl": 6, "list": [1, 3, 6], "benchmark": [2, 3, 4, 6], "n": [2, 6], "audio": [2, 5, 6], "random": [2, 6], "benchmerk": 6, "each": [3, 6], "modelwrapp": [0, 1], "abc": [1, 6], "convert_to_panda": 1, "datafram": [1, 2, 3], "convert": 1, "panda": [1, 3], "pd": [1, 3], "core": [1, 3], "frame": [1, 3], "abstract": [1, 6], "create_model": [1, 6], "save_to_csv": 1, "save_nam": [1, 3], "whisperbenchmark": 1, "model_bas": [1, 6], "path_to_dir": [1, 2, 6], "name": [1, 2, 6], "datasetbar": 2, "get_n_sampl": 2, "sampledataset": [1, 2, 6], "bare": 2, "df": [1, 2], "audio_id": [3, 5], "calul": 5, "durat": [], "m": 5, "print": [1, 2, 5], "from": [1, 2, 3, 5, 6], "modelvers": 6, "option": [3, 6], "default": [3, 6], "self": 6, "whispervers": 6, "none": 1, "save": [1, 3], "output": [1, 3], "csv": [1, 3], "filenam": [1, 3], "whisperapibenchmark": 1, "api": [1, 6], "whisperapi": 1, "local": [1, 6], "whisperapivers": 6, "whisper_1": 6, "1": 6, "whisperapiwrapp": 6, "openai_organ": 6, "openai_api_kei": 6, "need": 6, "env": 6, "current": 6, "directori": 6, "call": 6, "test": 1, "valid": [1, 3], "parent": [1, 6], "all": [1, 3], "just": 1, "share": 1, "child": [1, 6], "like": [1, 2, 3, 5, 6], "10": [1, 2, 6], "dataset_nam": [1, 2, 6], "set_dataset": [1, 6], "run": [1, 6], "wb": 1, "classmethod": 1, "update_sampl": 1, "updat": 1, "benchmark_results_to_csv": [1, 3], "result": [3, 6], "benchmark_results_2023": 3, "03": 3, "29_09": [], "21": [], "00": [], "default_csv_nam": 3, "multidispatch": 3, "allow": 3, "method": 3, "overload": 3, "implement": 6, "speech2text": [], "import": [1, 2, 3, 5, 6], "datetim": 1, "29_11": [], "27": [], "existing_id": 2, "trandom": 2, "dataset_n_random": 2, "extract": 2, "data": 2, "folder": 2, "regex_string_pars": 3, "regex": 3, "parc": 3, "up": 3, "ar": 3, "ha": 3, "8": 3, "de": 5, "stoel": 5, "heeft": 5, "krassen": 5, "gemaakt": 5, "op": 5, "vloer": 5, "id_from_dataset": 5, "modulewrapp": 6, "childmodelvers": 6, "demo": 6, "childmodelwrapp": 6, "def": 6, "__init__": 6, "modeltyp": 6, "transcrib": 6, "childbenchmark": 6, "model_nam": [3, 6], "version": 6, "append": 6, "existing_audio_id": 6, "choisen": 6, "arrai": 6, "44": [], "01": [], "54": [], "20": [], "29_17": [], "35": [], "24": [], "benchmark_results_to_html": 3, "dict_result": 3, "dict": 3, "titl": 3, "2023": 3, "html": 3, "overview": 3, "report": 3, "default_html_titl": 3, "default_html_nam": 3, "join_benchmark_result": 3, "set_index": 3, "join": 3, "can": 3, "save_benchmark_result": 3, "separate_benchmark_results_by_model": 3, "seper": 3, "30_10": 3, "14": 3, "04": 3}, "objects": {"speechtotext": [[1, 0, 0, "-", "benchmarks"], [2, 0, 0, "-", "datasets"], [3, 0, 0, "-", "functions"], [5, 0, 0, "-", "metrics"]], "speechtotext.benchmarks": [[1, 1, 1, "", "Benchmark"], [1, 1, 1, "", "WhisperAPIBenchmark"], [1, 1, 1, "", "WhisperBenchmark"]], "speechtotext.benchmarks.Benchmark": [[1, 2, 1, "id0", "BENCHMARK_SAMPLES"], [1, 2, 1, "id1", "DATASET"], [1, 3, 1, "", "convert_to_pandas"], [1, 3, 1, "", "create_models"], [1, 3, 1, "", "save_to_csv"], [1, 3, 1, "", "set_dataset"], [1, 3, 1, "", "update_samples"]], "speechtotext.benchmarks.WhisperAPIBenchmark": [[1, 2, 1, "", "MODEL_BASE"], [1, 3, 1, "", "create_models"]], "speechtotext.benchmarks.WhisperBenchmark": [[1, 2, 1, "", "MODEL_BASE"], [1, 3, 1, "", "create_models"]], "speechtotext.datasets": [[2, 1, 1, "", "Dataset"], [2, 1, 1, "", "DatasetBare"], [2, 1, 1, "", "SampleDataset"]], "speechtotext.datasets.Dataset": [[2, 3, 1, "", "get_n_samples"], [2, 3, 1, "", "load_transcript"]], "speechtotext.datasets.DatasetBare": [[2, 3, 1, "", "get_path_of_fragment"], [2, 3, 1, "", "get_text_of_id"], [2, 3, 1, "", "number_of_samples"]], "speechtotext.functions": [[3, 2, 1, "", "REGEX_STRING_PARSE"], [3, 4, 1, "", "benchmark_results_to_csv"], [3, 4, 1, "", "benchmark_results_to_html"], [3, 4, 1, "", "force_cudnn_initialization"], [3, 4, 1, "", "join_benchmark_results"], [3, 4, 1, "", "multidispatch"], [3, 4, 1, "", "save_benchmark_results"], [3, 4, 1, "", "separate_benchmark_results_by_model"], [3, 4, 1, "", "string_cleaning"]], "speechtotext.metrics": [[5, 1, 1, "", "Metrics"], [5, 4, 1, "", "notebook_metrics_print"]], "speechtotext.metrics.Metrics": [[5, 2, 1, "", "cer"], [5, 2, 1, "", "mer"], [5, 2, 1, "", "wer"], [5, 2, 1, "", "wil"], [5, 2, 1, "", "wip"]], "speechtotext.models": [[6, 0, 0, "-", "modelWrapper"], [6, 0, 0, "-", "whisperWrapper"]], "speechtotext.models.modelWrapper": [[6, 1, 1, "", "ModelVersion"], [6, 1, 1, "", "ModelWrapper"]], "speechtotext.models.modelWrapper.ModelWrapper": [[6, 3, 1, "", "benchmark_n_samples"], [6, 3, 1, "", "benchmark_sample"], [6, 3, 1, "", "benchmark_samples"], [6, 3, 1, "", "get_model"], [6, 3, 1, "", "get_transcript_of_file"]], "speechtotext.models.whisperWrapper": [[6, 1, 1, "", "WhisperAPIVersion"], [6, 1, 1, "", "WhisperAPIWrapper"], [6, 1, 1, "", "WhisperVersion"], [6, 1, 1, "", "WhisperWrapper"]], "speechtotext.models.whisperWrapper.WhisperAPIVersion": [[6, 2, 1, "", "WHISPER_1"]], "speechtotext.models.whisperWrapper.WhisperAPIWrapper": [[6, 3, 1, "", "get_model"], [6, 3, 1, "", "get_transcript_of_file"]], "speechtotext.models.whisperWrapper.WhisperVersion": [[6, 2, 1, "", "BASE"], [6, 2, 1, "", "LARGE"], [6, 2, 1, "", "MEDIUM"], [6, 2, 1, "", "SMALL"], [6, 2, 1, "", "TINY"]], "speechtotext.models.whisperWrapper.WhisperWrapper": [[6, 3, 1, "", "get_model"], [6, 3, 1, "", "get_transcript_of_file"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:attribute", "3": "py:method", "4": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "attribute", "Python attribute"], "3": ["py", "method", "Python method"], "4": ["py", "function", "Python function"]}, "titleterms": {"pid": [], "packagenam": [], "modul": [1, 2, 3, 5, 6], "welcom": 0, "": 0, "document": 0, "content": [0, 4], "indic": 0, "tabl": 0, "function": 3, "packag": [4, 6], "submodul": [4, 6], "info": [], "speechtotext": [0, 1, 2, 3, 4, 5, 6], "dataset": 2, "metric": 5, "model": 6, "whisperwrapp": 6, "benchmark": 1, "modelwrapp": 6}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Welcome to speechtotext\u2019s documentation!": [[0, "welcome-to-speechtotext-s-documentation"]], "Contents:": [[0, null], [4, null]], "Indices and tables": [[0, "indices-and-tables"]], "Benchmarks": [[1, "benchmarks"]], "speechtotext.benchmarks module": [[1, "module-speechtotext.benchmarks"]], "Datasets": [[2, "datasets"]], "speechtotext.datasets module": [[2, "module-speechtotext.datasets"]], "Functions": [[3, "functions"]], "speechtotext.functions module": [[3, "module-speechtotext.functions"]], "Speechtotext package": [[4, "speechtotext-package"]], "Submodules": [[4, "submodules"], [6, "submodules"]], "Metrics": [[5, "metrics"]], "speechtotext.metrics module": [[5, "module-speechtotext.metrics"]], "Speechtotext models package": [[6, "speechtotext-models-package"]], "speechtotext.models.modelWrapper module": [[6, "module-speechtotext.models.modelWrapper"]], "speechtotext.models.whisperWrapper module": [[6, "module-speechtotext.models.whisperWrapper"]]}, "indexentries": {"benchmark_samples (speechtotext.benchmarks.benchmark attribute)": [[1, "id0"], [1, "speechtotext.benchmarks.Benchmark.BENCHMARK_SAMPLES"]], "benchmark (class in speechtotext.benchmarks)": [[1, "speechtotext.benchmarks.Benchmark"]], "dataset (speechtotext.benchmarks.benchmark attribute)": [[1, "id1"], [1, "speechtotext.benchmarks.Benchmark.DATASET"]], "model_base (speechtotext.benchmarks.whisperapibenchmark attribute)": [[1, "speechtotext.benchmarks.WhisperAPIBenchmark.MODEL_BASE"]], "model_base (speechtotext.benchmarks.whisperbenchmark attribute)": [[1, "speechtotext.benchmarks.WhisperBenchmark.MODEL_BASE"]], "whisperapibenchmark (class in speechtotext.benchmarks)": [[1, "speechtotext.benchmarks.WhisperAPIBenchmark"]], "whisperbenchmark (class in speechtotext.benchmarks)": [[1, "speechtotext.benchmarks.WhisperBenchmark"]], "convert_to_pandas() (speechtotext.benchmarks.benchmark method)": [[1, "speechtotext.benchmarks.Benchmark.convert_to_pandas"]], "create_models() (speechtotext.benchmarks.benchmark method)": [[1, "speechtotext.benchmarks.Benchmark.create_models"]], "create_models() (speechtotext.benchmarks.whisperapibenchmark method)": [[1, "speechtotext.benchmarks.WhisperAPIBenchmark.create_models"]], "create_models() (speechtotext.benchmarks.whisperbenchmark method)": [[1, "speechtotext.benchmarks.WhisperBenchmark.create_models"]], "module": [[1, "module-speechtotext.benchmarks"], [2, "module-speechtotext.datasets"], [3, "module-speechtotext.functions"], [5, "module-speechtotext.metrics"], [6, "module-speechtotext.models.modelWrapper"], [6, "module-speechtotext.models.whisperWrapper"]], "save_to_csv() (speechtotext.benchmarks.benchmark method)": [[1, "speechtotext.benchmarks.Benchmark.save_to_csv"]], "set_dataset() (speechtotext.benchmarks.benchmark class method)": [[1, "speechtotext.benchmarks.Benchmark.set_dataset"]], "speechtotext.benchmarks": [[1, "module-speechtotext.benchmarks"]], "update_samples() (speechtotext.benchmarks.benchmark class method)": [[1, "speechtotext.benchmarks.Benchmark.update_samples"]], "dataset (class in speechtotext.datasets)": [[2, "speechtotext.datasets.Dataset"]], "datasetbare (class in speechtotext.datasets)": [[2, "speechtotext.datasets.DatasetBare"]], "sampledataset (class in speechtotext.datasets)": [[2, "speechtotext.datasets.SampleDataset"]], "get_n_samples() (speechtotext.datasets.dataset method)": [[2, "speechtotext.datasets.Dataset.get_n_samples"]], "get_path_of_fragment() (speechtotext.datasets.datasetbare method)": [[2, "speechtotext.datasets.DatasetBare.get_path_of_fragment"]], "get_text_of_id() (speechtotext.datasets.datasetbare method)": [[2, "speechtotext.datasets.DatasetBare.get_text_of_id"]], "load_transcript() (speechtotext.datasets.dataset method)": [[2, "speechtotext.datasets.Dataset.load_transcript"]], "number_of_samples() (speechtotext.datasets.datasetbare method)": [[2, "speechtotext.datasets.DatasetBare.number_of_samples"]], "speechtotext.datasets": [[2, "module-speechtotext.datasets"]], "regex_string_parse (in module speechtotext.functions)": [[3, "speechtotext.functions.REGEX_STRING_PARSE"]], "benchmark_results_to_csv() (in module speechtotext.functions)": [[3, "speechtotext.functions.benchmark_results_to_csv"]], "benchmark_results_to_html() (in module speechtotext.functions)": [[3, "speechtotext.functions.benchmark_results_to_html"]], "force_cudnn_initialization() (in module speechtotext.functions)": [[3, "speechtotext.functions.force_cudnn_initialization"]], "join_benchmark_results() (in module speechtotext.functions)": [[3, "speechtotext.functions.join_benchmark_results"]], "multidispatch() (in module speechtotext.functions)": [[3, "speechtotext.functions.multidispatch"]], "save_benchmark_results() (in module speechtotext.functions)": [[3, "speechtotext.functions.save_benchmark_results"]], "separate_benchmark_results_by_model() (in module speechtotext.functions)": [[3, "speechtotext.functions.separate_benchmark_results_by_model"]], "speechtotext.functions": [[3, "module-speechtotext.functions"]], "string_cleaning() (in module speechtotext.functions)": [[3, "speechtotext.functions.string_cleaning"]], "metrics (class in speechtotext.metrics)": [[5, "speechtotext.metrics.Metrics"]], "cer (speechtotext.metrics.metrics attribute)": [[5, "speechtotext.metrics.Metrics.cer"]], "mer (speechtotext.metrics.metrics attribute)": [[5, "speechtotext.metrics.Metrics.mer"]], "notebook_metrics_print() (in module speechtotext.metrics)": [[5, "speechtotext.metrics.notebook_metrics_print"]], "speechtotext.metrics": [[5, "module-speechtotext.metrics"]], "wer (speechtotext.metrics.metrics attribute)": [[5, "speechtotext.metrics.Metrics.wer"]], "wil (speechtotext.metrics.metrics attribute)": [[5, "speechtotext.metrics.Metrics.wil"]], "wip (speechtotext.metrics.metrics attribute)": [[5, "speechtotext.metrics.Metrics.wip"]], "base (speechtotext.models.whisperwrapper.whisperversion attribute)": [[6, "speechtotext.models.whisperWrapper.WhisperVersion.BASE"]], "large (speechtotext.models.whisperwrapper.whisperversion attribute)": [[6, "speechtotext.models.whisperWrapper.WhisperVersion.LARGE"]], "medium (speechtotext.models.whisperwrapper.whisperversion attribute)": [[6, "speechtotext.models.whisperWrapper.WhisperVersion.MEDIUM"]], "modelversion (class in speechtotext.models.modelwrapper)": [[6, "speechtotext.models.modelWrapper.ModelVersion"]], "modelwrapper (class in speechtotext.models.modelwrapper)": [[6, "speechtotext.models.modelWrapper.ModelWrapper"]], "small (speechtotext.models.whisperwrapper.whisperversion attribute)": [[6, "speechtotext.models.whisperWrapper.WhisperVersion.SMALL"]], "tiny (speechtotext.models.whisperwrapper.whisperversion attribute)": [[6, "speechtotext.models.whisperWrapper.WhisperVersion.TINY"]], "whisper_1 (speechtotext.models.whisperwrapper.whisperapiversion attribute)": [[6, "speechtotext.models.whisperWrapper.WhisperAPIVersion.WHISPER_1"]], "whisperapiversion (class in speechtotext.models.whisperwrapper)": [[6, "speechtotext.models.whisperWrapper.WhisperAPIVersion"]], "whisperapiwrapper (class in speechtotext.models.whisperwrapper)": [[6, "speechtotext.models.whisperWrapper.WhisperAPIWrapper"]], "whisperversion (class in speechtotext.models.whisperwrapper)": [[6, "speechtotext.models.whisperWrapper.WhisperVersion"]], "whisperwrapper (class in speechtotext.models.whisperwrapper)": [[6, "speechtotext.models.whisperWrapper.WhisperWrapper"]], "benchmark_n_samples() (speechtotext.models.modelwrapper.modelwrapper method)": [[6, "speechtotext.models.modelWrapper.ModelWrapper.benchmark_n_samples"]], "benchmark_sample() (speechtotext.models.modelwrapper.modelwrapper method)": [[6, "speechtotext.models.modelWrapper.ModelWrapper.benchmark_sample"]], "benchmark_samples() (speechtotext.models.modelwrapper.modelwrapper method)": [[6, "speechtotext.models.modelWrapper.ModelWrapper.benchmark_samples"]], "get_model() (speechtotext.models.modelwrapper.modelwrapper method)": [[6, "speechtotext.models.modelWrapper.ModelWrapper.get_model"]], "get_model() (speechtotext.models.whisperwrapper.whisperapiwrapper method)": [[6, "speechtotext.models.whisperWrapper.WhisperAPIWrapper.get_model"]], "get_model() (speechtotext.models.whisperwrapper.whisperwrapper method)": [[6, "speechtotext.models.whisperWrapper.WhisperWrapper.get_model"]], "get_transcript_of_file() (speechtotext.models.modelwrapper.modelwrapper method)": [[6, "speechtotext.models.modelWrapper.ModelWrapper.get_transcript_of_file"]], "get_transcript_of_file() (speechtotext.models.whisperwrapper.whisperapiwrapper method)": [[6, "speechtotext.models.whisperWrapper.WhisperAPIWrapper.get_transcript_of_file"]], "get_transcript_of_file() (speechtotext.models.whisperwrapper.whisperwrapper method)": [[6, "speechtotext.models.whisperWrapper.WhisperWrapper.get_transcript_of_file"]], "speechtotext.models.modelwrapper": [[6, "module-speechtotext.models.modelWrapper"]], "speechtotext.models.whisperwrapper": [[6, "module-speechtotext.models.whisperWrapper"]]}})