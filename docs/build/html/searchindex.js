Search.setIndex({"docnames": ["index", "speechtotext/benchmarks", "speechtotext/datasets", "speechtotext/functions", "speechtotext/index", "speechtotext/metrics", "speechtotext/models/index"], "filenames": ["index.rst", "speechtotext/benchmarks.rst", "speechtotext/datasets.rst", "speechtotext/functions.rst", "speechtotext/index.rst", "speechtotext/metrics.rst", "speechtotext/models/index.rst"], "titles": ["Welcome to speechtotext\u2019s documentation!", "Benchmarks", "Datasets", "Functions", "Speechtotext package", "Metrics", "Speechtotext models package"], "terms": {"class": [1, 2, 5, 6], "base": [1, 2, 5, 6], "object": [2, 5], "set": 6, "proport": [], "integr": [], "deriv": [], "control": [], "genout": [], "error": 5, "float": 5, "calcul": [], "paramet": [2, 3, 5, 6], "valu": 6, "return": [1, 2, 3, 6], "type": [1, 2, 3, 5, 6], "initi": [], "variabl": [], "setkd": [], "invar": [], "k_": [], "d": [], "setki": [], "i": [], "setkp": [], "p": [], "setpreverror": [], "preverror": [], "previou": [], "packag": 0, "submodul": 0, "info": [], "modul": [0, 4], "function": 4, "pid": [], "index": 0, "search": 0, "page": 0, "threadsafesingleton": [], "creat": 1, "device_exist": [], "path": [2, 6], "str": [1, 2, 3, 5, 6], "bool": 6, "thi": [], "check": [], "an": 1, "devic": [], "exist": 2, "linux": [], "dev": [], "tty": [], "exampl": [], "true": [1, 5, 6], "set_max_limit": [], "int": [2, 6], "max": [], "maximum": [], "limit": [], "2": [], "set_min_limit": [], "min": [], "minimum": [], "get_cpu_tempfunc": [], "cpu": [], "temperatur": [], "get_cpu_us": [], "usag": [], "us": 3, "psutil": [], "get_gpu_tempfunc": [], "gpu": [], "charact": 5, "string": [2, 3], "get_ram_info": [], "ram": [], "get_swap_info": [], "swap": [], "memori": [], "packagenam": [], "dataset": [1, 4, 5, 6], "metric": [1, 4, 6], "dir": [], "file_ext": 2, "wav": 2, "get_path_of_frag": 2, "id": [2, 5, 6], "get": [2, 6], "fragment": 2, "file": [2, 6], "rais": 2, "filenotfounderror": 2, "doesn": 2, "t": 2, "_description_": [2, 5], "get_text_of_id": 2, "text": [2, 3], "spoken": 2, "load_transcript": 2, "load": 2, "transcript": [2, 5, 6], "refer": 5, "hypothesi": 5, "with_clean": [1, 5, 6], "_summary_": [], "attribut": 5, "class_attribut": 5, "The": 5, "wer": 5, "word": 5, "rate": 5, "mer": 5, "match": 5, "wil": 5, "inform": 5, "lost": 5, "wip": 5, "preserv": 5, "cer": 5, "notebook_metrics_print": 5, "string_clean": 3, "clean": [3, 6], "stt": 3, "unclean": 3, "model": [0, 1], "whisperwrapp": 0, "force_cudnn_initi": 3, "forc": 3, "cuda": 3, "torch": 3, "whisper": [1, 6], "model_vers": 6, "whispermodel": 6, "model_dir": 6, "benchmark_sampl": 6, "get_model": 6, "get_transcript_of_fil": 6, "audio_file_nam": 6, "enum": 6, "enumer": [], "larg": 6, "medium": 6, "small": 6, "tini": 6, "number_of_sampl": [2, 6], "number": [2, 6], "sampl": [2, 6], "avail": 6, "wrapper": [1, 6], "benchmark_n_sampl": 6, "list": [1, 6], "benchmark": [4, 6], "n": [2, 6], "audio": [5, 6], "random": [2, 6], "benchmerk": 6, "each": 6, "modelwrapp": [0, 1], "abc": [1, 6], "convert_to_panda": 1, "datafram": [1, 2], "convert": 1, "panda": 1, "pd": 1, "core": 1, "frame": 1, "abstract": [1, 6], "create_model": 1, "save_to_csv": 1, "save_nam": 1, "whisperbenchmark": 1, "model_bas": 1, "path_to_dir": 2, "name": 2, "datasetbar": 2, "get_n_sampl": 2, "sampledataset": [2, 6], "bare": 2, "df": 2, "audio_id": 5, "calul": 5, "durat": [], "m": [], "print": 5, "from": 5, "modelvers": 6, "option": 6, "default": 6, "self": 6, "whispervers": 6}, "objects": {"speechtotext": [[1, 0, 0, "-", "benchmarks"], [2, 0, 0, "-", "datasets"], [3, 0, 0, "-", "functions"], [5, 0, 0, "-", "metrics"]], "speechtotext.benchmarks": [[1, 1, 1, "", "Benchmark"], [1, 1, 1, "", "WhisperBenchmark"]], "speechtotext.benchmarks.Benchmark": [[1, 2, 1, "", "convert_to_pandas"], [1, 2, 1, "", "create_models"], [1, 2, 1, "", "save_to_csv"]], "speechtotext.benchmarks.WhisperBenchmark": [[1, 3, 1, "", "MODEL_BASE"], [1, 2, 1, "", "create_models"]], "speechtotext.datasets": [[2, 1, 1, "", "Dataset"], [2, 1, 1, "", "DatasetBare"], [2, 1, 1, "", "SampleDataset"]], "speechtotext.datasets.Dataset": [[2, 2, 1, "", "get_n_samples"], [2, 2, 1, "", "load_transcript"]], "speechtotext.datasets.DatasetBare": [[2, 2, 1, "", "get_path_of_fragment"], [2, 2, 1, "", "get_text_of_id"], [2, 2, 1, "", "number_of_samples"]], "speechtotext.functions": [[3, 4, 1, "", "force_cudnn_initialization"], [3, 4, 1, "", "string_cleaning"]], "speechtotext.metrics": [[5, 1, 1, "", "Metrics"], [5, 4, 1, "", "notebook_metrics_print"]], "speechtotext.metrics.Metrics": [[5, 3, 1, "", "cer"], [5, 3, 1, "", "mer"], [5, 3, 1, "", "wer"], [5, 3, 1, "", "wil"], [5, 3, 1, "", "wip"]], "speechtotext.models": [[6, 0, 0, "-", "modelWrapper"], [6, 0, 0, "-", "whisperWrapper"]], "speechtotext.models.modelWrapper": [[6, 1, 1, "", "ModelVersion"], [6, 1, 1, "", "ModelWrapper"]], "speechtotext.models.modelWrapper.ModelWrapper": [[6, 2, 1, "", "benchmark_n_samples"], [6, 2, 1, "", "benchmark_sample"], [6, 2, 1, "", "benchmark_samples"], [6, 2, 1, "", "get_model"], [6, 2, 1, "", "get_transcript_of_file"]], "speechtotext.models.whisperWrapper": [[6, 1, 1, "", "WhisperVersion"], [6, 1, 1, "", "WhisperWrapper"]], "speechtotext.models.whisperWrapper.WhisperVersion": [[6, 3, 1, "", "BASE"], [6, 3, 1, "", "LARGE"], [6, 3, 1, "", "MEDIUM"], [6, 3, 1, "", "SMALL"], [6, 3, 1, "", "TINY"]], "speechtotext.models.whisperWrapper.WhisperWrapper": [[6, 3, 1, "", "MODEL_DIR"], [6, 2, 1, "", "get_model"], [6, 2, 1, "", "get_transcript_of_file"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "function", "Python function"]}, "titleterms": {"pid": [], "packagenam": [], "modul": [1, 2, 3, 5, 6], "welcom": 0, "": 0, "document": 0, "content": [0, 4], "indic": 0, "tabl": 0, "function": 3, "packag": [4, 6], "submodul": [4, 6], "info": [], "speechtotext": [0, 1, 2, 3, 4, 5, 6], "dataset": 2, "metric": 5, "model": 6, "whisperwrapp": 6, "benchmark": 1, "modelwrapp": 6}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx": 57}, "alltitles": {"Welcome to speechtotext\u2019s documentation!": [[0, "welcome-to-speechtotext-s-documentation"]], "Contents:": [[0, null], [4, null]], "Indices and tables": [[0, "indices-and-tables"]], "Benchmarks": [[1, "benchmarks"]], "speechtotext.benchmarks module": [[1, "module-speechtotext.benchmarks"]], "Datasets": [[2, "datasets"]], "speechtotext.datasets module": [[2, "module-speechtotext.datasets"]], "Functions": [[3, "functions"]], "speechtotext.functions module": [[3, "module-speechtotext.functions"]], "Speechtotext package": [[4, "speechtotext-package"]], "Submodules": [[4, "submodules"], [6, "submodules"]], "Metrics": [[5, "metrics"]], "speechtotext.metrics module": [[5, "module-speechtotext.metrics"]], "Speechtotext models package": [[6, "speechtotext-models-package"]], "speechtotext.models.modelWrapper module": [[6, "module-speechtotext.models.modelWrapper"]], "speechtotext.models.whisperWrapper module": [[6, "module-speechtotext.models.whisperWrapper"]]}, "indexentries": {"benchmark (class in speechtotext.benchmarks)": [[1, "speechtotext.benchmarks.Benchmark"]], "model_base (speechtotext.benchmarks.whisperbenchmark attribute)": [[1, "speechtotext.benchmarks.WhisperBenchmark.MODEL_BASE"]], "whisperbenchmark (class in speechtotext.benchmarks)": [[1, "speechtotext.benchmarks.WhisperBenchmark"]], "convert_to_pandas() (speechtotext.benchmarks.benchmark method)": [[1, "speechtotext.benchmarks.Benchmark.convert_to_pandas"]], "create_models() (speechtotext.benchmarks.benchmark method)": [[1, "speechtotext.benchmarks.Benchmark.create_models"]], "create_models() (speechtotext.benchmarks.whisperbenchmark method)": [[1, "speechtotext.benchmarks.WhisperBenchmark.create_models"]], "module": [[1, "module-speechtotext.benchmarks"], [2, "module-speechtotext.datasets"], [3, "module-speechtotext.functions"], [5, "module-speechtotext.metrics"], [6, "module-speechtotext.models.modelWrapper"], [6, "module-speechtotext.models.whisperWrapper"]], "save_to_csv() (speechtotext.benchmarks.benchmark method)": [[1, "speechtotext.benchmarks.Benchmark.save_to_csv"]], "speechtotext.benchmarks": [[1, "module-speechtotext.benchmarks"]], "dataset (class in speechtotext.datasets)": [[2, "speechtotext.datasets.Dataset"]], "datasetbare (class in speechtotext.datasets)": [[2, "speechtotext.datasets.DatasetBare"]], "sampledataset (class in speechtotext.datasets)": [[2, "speechtotext.datasets.SampleDataset"]], "get_n_samples() (speechtotext.datasets.dataset method)": [[2, "speechtotext.datasets.Dataset.get_n_samples"]], "get_path_of_fragment() (speechtotext.datasets.datasetbare method)": [[2, "speechtotext.datasets.DatasetBare.get_path_of_fragment"]], "get_text_of_id() (speechtotext.datasets.datasetbare method)": [[2, "speechtotext.datasets.DatasetBare.get_text_of_id"]], "load_transcript() (speechtotext.datasets.dataset method)": [[2, "speechtotext.datasets.Dataset.load_transcript"]], "number_of_samples() (speechtotext.datasets.datasetbare method)": [[2, "speechtotext.datasets.DatasetBare.number_of_samples"]], "speechtotext.datasets": [[2, "module-speechtotext.datasets"]], "force_cudnn_initialization() (in module speechtotext.functions)": [[3, "speechtotext.functions.force_cudnn_initialization"]], "speechtotext.functions": [[3, "module-speechtotext.functions"]], "string_cleaning() (in module speechtotext.functions)": [[3, "speechtotext.functions.string_cleaning"]], "metrics (class in speechtotext.metrics)": [[5, "speechtotext.metrics.Metrics"]], "cer (speechtotext.metrics.metrics attribute)": [[5, "speechtotext.metrics.Metrics.cer"]], "mer (speechtotext.metrics.metrics attribute)": [[5, "speechtotext.metrics.Metrics.mer"]], "notebook_metrics_print() (in module speechtotext.metrics)": [[5, "speechtotext.metrics.notebook_metrics_print"]], "speechtotext.metrics": [[5, "module-speechtotext.metrics"]], "wer (speechtotext.metrics.metrics attribute)": [[5, "speechtotext.metrics.Metrics.wer"]], "wil (speechtotext.metrics.metrics attribute)": [[5, "speechtotext.metrics.Metrics.wil"]], "wip (speechtotext.metrics.metrics attribute)": [[5, "speechtotext.metrics.Metrics.wip"]], "base (speechtotext.models.whisperwrapper.whisperversion attribute)": [[6, "speechtotext.models.whisperWrapper.WhisperVersion.BASE"]], "large (speechtotext.models.whisperwrapper.whisperversion attribute)": [[6, "speechtotext.models.whisperWrapper.WhisperVersion.LARGE"]], "medium (speechtotext.models.whisperwrapper.whisperversion attribute)": [[6, "speechtotext.models.whisperWrapper.WhisperVersion.MEDIUM"]], "model_dir (speechtotext.models.whisperwrapper.whisperwrapper attribute)": [[6, "speechtotext.models.whisperWrapper.WhisperWrapper.MODEL_DIR"]], "modelversion (class in speechtotext.models.modelwrapper)": [[6, "speechtotext.models.modelWrapper.ModelVersion"]], "modelwrapper (class in speechtotext.models.modelwrapper)": [[6, "speechtotext.models.modelWrapper.ModelWrapper"]], "small (speechtotext.models.whisperwrapper.whisperversion attribute)": [[6, "speechtotext.models.whisperWrapper.WhisperVersion.SMALL"]], "tiny (speechtotext.models.whisperwrapper.whisperversion attribute)": [[6, "speechtotext.models.whisperWrapper.WhisperVersion.TINY"]], "whisperversion (class in speechtotext.models.whisperwrapper)": [[6, "speechtotext.models.whisperWrapper.WhisperVersion"]], "whisperwrapper (class in speechtotext.models.whisperwrapper)": [[6, "speechtotext.models.whisperWrapper.WhisperWrapper"]], "benchmark_n_samples() (speechtotext.models.modelwrapper.modelwrapper method)": [[6, "speechtotext.models.modelWrapper.ModelWrapper.benchmark_n_samples"]], "benchmark_sample() (speechtotext.models.modelwrapper.modelwrapper method)": [[6, "speechtotext.models.modelWrapper.ModelWrapper.benchmark_sample"]], "benchmark_samples() (speechtotext.models.modelwrapper.modelwrapper method)": [[6, "speechtotext.models.modelWrapper.ModelWrapper.benchmark_samples"]], "get_model() (speechtotext.models.modelwrapper.modelwrapper method)": [[6, "speechtotext.models.modelWrapper.ModelWrapper.get_model"]], "get_model() (speechtotext.models.whisperwrapper.whisperwrapper method)": [[6, "speechtotext.models.whisperWrapper.WhisperWrapper.get_model"]], "get_transcript_of_file() (speechtotext.models.modelwrapper.modelwrapper method)": [[6, "speechtotext.models.modelWrapper.ModelWrapper.get_transcript_of_file"]], "get_transcript_of_file() (speechtotext.models.whisperwrapper.whisperwrapper method)": [[6, "speechtotext.models.whisperWrapper.WhisperWrapper.get_transcript_of_file"]], "speechtotext.models.modelwrapper": [[6, "module-speechtotext.models.modelWrapper"]], "speechtotext.models.whisperwrapper": [[6, "module-speechtotext.models.whisperWrapper"]]}})